#!/usr/bin/python
# -*- coding:utf-8 -*-
"""
Created on 2025/11/03
@author  : William_Trouvaille
@function: è®­ç»ƒåè°ƒå™¨æ¨¡å—
@detail: æä¾›é«˜åº¦å¯å¤ç”¨ã€å¯æ‰©å±•çš„ Trainer ç±»ï¼Œç”¨äºŽæ ‡å‡† PyTorch è®­ç»ƒæµç¨‹
"""

import time
import traceback
from typing import Dict, Any, Optional, Union, List, Literal

import torch
import torch.nn as nn
from torch.cuda.amp import autocast, GradScaler
from torch.optim import Optimizer
from torch.optim.lr_scheduler import _LRScheduler, ReduceLROnPlateau
from torch.utils.data import DataLoader
from loguru import logger

from .checkpoint_manager import CheckpointManager
from .early_stopping import EarlyStopper
from .helpers import clear_memory, get_memory_usage, log_memory_usage, format_time
from .metrics import MetricTracker, AverageMeter
from .ntfy_notifier import NtfyNotifier
from .progress import Progress


class Trainer:
    """
    å¯å¤ç”¨çš„ PyTorch è®­ç»ƒåè°ƒå™¨ã€‚

    è®¾è®¡ç†å¿µ:
        - èŒè´£åˆ†ç¦»: é€šè¿‡ä¾èµ–æ³¨å…¥æŽ¥æ”¶æ‰€æœ‰æ ¸å¿ƒç»„ä»¶
        - æ¨¡æ¿æ–¹æ³•: æä¾›å¯é‡å†™çš„ _train_step/_eval_step æ”¯æŒè‡ªå®šä¹‰é€»è¾‘
        - æ€§èƒ½ä¼˜å…ˆ: é›†æˆ AMPã€æ¢¯åº¦ç´¯ç§¯ã€é«˜æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ª
        - åŒæž„é€ æ¨¡å¼: æ”¯æŒ DI æ¨¡å¼å’Œ from_config æ¨¡å¼

    ä½¿ç”¨åœºæ™¯:
        åœºæ™¯1 - DIæ¨¡å¼ (æŽ¨è, æœ€å¤§çµæ´»æ€§):
            ckpt_mgr = CheckpointManager(...)
            stopper = EarlyStopper(...)

            trainer = Trainer(
                model=model,
                optimizer=optimizer,
                criterion=criterion,
                device=device,
                checkpoint_manager=ckpt_mgr,
                early_stopper=stopper,
                use_amp=True
            )
            trainer.fit(train_loader, val_loader, epochs=100)

        åœºæ™¯2 - from_configæ¨¡å¼ (æŽ¨è, å¤§åž‹é¡¹ç›®):
            trainer = Trainer.from_config(
                model=model,
                optimizer=optimizer,
                criterion=criterion,
                device=device,
                config=config
            )
            trainer.fit(train_loader, val_loader)

        åœºæ™¯3 - è‡ªå®šä¹‰è®­ç»ƒ (ç»§æ‰¿):
            class MyTrainer(Trainer):
                def _train_step(self, batch):
                    # å¤šä»»åŠ¡ã€GANã€å¯¹æ¯”å­¦ä¹ ç­‰è‡ªå®šä¹‰é€»è¾‘
                    ...
    """

    def __init__(
            self,
            model: nn.Module,
            optimizer: Optimizer,
            criterion: nn.Module,
            device: Union[str, torch.device],

            # å¯é€‰å·¥å…· (é€šè¿‡ä¾èµ–æ³¨å…¥)
            checkpoint_manager: Optional[CheckpointManager] = None,
            early_stopper: Optional[EarlyStopper] = None,
            notifier: Optional[NtfyNotifier] = None,
            scheduler: Optional[_LRScheduler] = None,

            # æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
            use_amp: bool = False,
            grad_accum_steps: int = 1,
            max_grad_norm: Optional[float] = None,

            # æŒ‡æ ‡ä¸Žæ—¥å¿—é…ç½®
            metric_to_track: str = 'acc',
            metric_mode: Literal['min', 'max'] = 'max',
            compute_top5: bool = False,
            log_interval: int = 1,
            val_interval: int = 1,

            # å…¶ä»–é…ç½®
            auto_resume: bool = True
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨ (ä¾èµ–æ³¨å…¥æ¨¡å¼)ã€‚

        å‚æ•°:
            model (nn.Module): PyTorch æ¨¡åž‹ (åº”å·²ç§»åˆ°ç›®æ ‡è®¾å¤‡)
            optimizer (Optimizer): PyTorch ä¼˜åŒ–å™¨
            criterion (nn.Module): æŸå¤±å‡½æ•°
            device (str | torch.device): è®¡ç®—è®¾å¤‡

            checkpoint_manager (CheckpointManager, optional): æ£€æŸ¥ç‚¹ç®¡ç†å™¨
            early_stopper (EarlyStopper, optional): æ—©åœå™¨
            notifier (NtfyNotifier, optional): Ntfy é€šçŸ¥å™¨
            scheduler (_LRScheduler, optional): å­¦ä¹ çŽ‡è°ƒåº¦å™¨

            use_amp (bool): æ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ (é»˜è®¤: False)
            grad_accum_steps (int): æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (é»˜è®¤: 1)
            max_grad_norm (float, optional): æ¢¯åº¦è£å‰ªçš„æœ€å¤§èŒƒæ•°

            metric_to_track (str): æ—©åœå’Œæœ€ä½³æ¨¡åž‹è·Ÿè¸ªçš„æŒ‡æ ‡ (é»˜è®¤: 'acc')
            metric_mode (str): 'max' æˆ– 'min' (é»˜è®¤: 'max')
            compute_top5 (bool): æ˜¯å¦è®¡ç®— Top-5 å‡†ç¡®çŽ‡ (é»˜è®¤: False)
            log_interval (int): æ¯éš”å¤šå°‘ä¸ª epoch è®°å½•è¯¦ç»†æ—¥å¿— (é»˜è®¤: 1)
            val_interval (int): æ¯éš”å¤šå°‘ä¸ª epoch éªŒè¯ä¸€æ¬¡ (é»˜è®¤: 1)

            auto_resume (bool): æ˜¯å¦è‡ªåŠ¨ä»Žæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ (é»˜è®¤: True)
        """
        logger.info("Trainer åˆå§‹åŒ– (DI æ¨¡å¼)...")

        # ========== 1. æ ¸å¿ƒç»„ä»¶ ==========
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion

        if isinstance(device, str):
            device = torch.device(device)
        self.device = device
        self.scheduler = scheduler

        logger.info(f"è®¾å¤‡: {self.device}")

        # ========== 2. å¯é€‰å·¥å…· ==========
        self.checkpoint_manager = checkpoint_manager
        self.early_stopper = early_stopper
        self.notifier = notifier

        # ========== 3. æ€§èƒ½ä¼˜åŒ– ==========
        self.use_amp = use_amp
        self.grad_accum_steps = max(1, grad_accum_steps)
        self.max_grad_norm = max_grad_norm

        self.scaler = GradScaler(enabled=(use_amp and self.device.type == 'cuda'))

        if self.scaler.is_enabled():
            logger.info("AMP (è‡ªåŠ¨æ··åˆç²¾åº¦) å·²å¯ç”¨")
        if self.grad_accum_steps > 1:
            logger.info(f"æ¢¯åº¦ç´¯ç§¯å·²å¯ç”¨ï¼Œç´¯ç§¯æ­¥æ•°: {self.grad_accum_steps}")
        if self.max_grad_norm is not None:
            logger.info(f"æ¢¯åº¦è£å‰ªå·²å¯ç”¨ï¼Œæœ€å¤§èŒƒæ•°: {self.max_grad_norm}")

        # ========== 4. æŒ‡æ ‡ä¸Žæ—¥å¿— ==========
        self.metric_to_track = metric_to_track
        self.metric_mode = metric_mode
        self.log_interval = max(1, log_interval)
        self.val_interval = max(1, val_interval)

        # è‡ªåŠ¨å®žä¾‹åŒ–å†…éƒ¨å·¥å…·
        self.metric_tracker = MetricTracker(self.device, compute_top5=compute_top5)
        self.lr_meter = AverageMeter()

        # ========== 5. å†…éƒ¨çŠ¶æ€ ==========
        self.start_epoch = 0
        self.current_epoch = 0
        self.global_step = 0
        self.best_metric = -float('inf') if self.metric_mode == 'max' else float('inf')
        self.training_history: List[Dict[str, float]] = []
        self.interrupt_state: Dict[str, Any] = {}

        # ========== 6. è‡ªåŠ¨æ¢å¤æ£€æŸ¥ç‚¹ ==========
        if auto_resume and self.checkpoint_manager:
            self._load_checkpoint()

        logger.success("Trainer åˆå§‹åŒ–å®Œæˆ")

    @classmethod
    def from_config(
            cls,
            model: nn.Module,
            optimizer: Optimizer,
            criterion: nn.Module,
            device: Union[str, torch.device],
            config: Any,
            scheduler: Optional[_LRScheduler] = None
    ) -> 'Trainer':
        """
        ä»Žé…ç½®å¯¹è±¡åˆ›å»º Trainer å®žä¾‹ (é€‚åˆå¤§åž‹é¡¹ç›®)ã€‚

        å‚æ•°:
            model, optimizer, criterion, device, scheduler: åŒ __init__
            config (ConfigNamespace): åŒ…å« training/checkpoint/ntfy å­é…ç½®çš„å®Œæ•´é…ç½®å¯¹è±¡

        è¿”å›ž:
            Trainer: é…ç½®å¥½çš„ Trainer å®žä¾‹

        ç¤ºä¾‹:
            config = setup_config(...)
            trainer = Trainer.from_config(
                model=model,
                optimizer=optimizer,
                criterion=criterion,
                device=device,
                config=config
            )
        """
        logger.info("Trainer åˆå§‹åŒ– (from_config æ¨¡å¼)...")

        # ä»Ž config è‡ªåŠ¨å®žä¾‹åŒ–æ‰€æœ‰å·¥å…·
        try:
            train_cfg = config.training
            ckpt_cfg = config.checkpoint
            ntfy_cfg = config.ntfy
        except AttributeError as e:
            logger.error(f"é…ç½®å¯¹è±¡ç¼ºå°‘å¿…éœ€çš„å­é…ç½®: {e}")
            raise ValueError(f"é…ç½®å¯¹è±¡ä¸å®Œæ•´: {e}")

        # å®žä¾‹åŒ–å·¥å…·
        ckpt_mgr = CheckpointManager(
            save_dir=ckpt_cfg.save_dir,
            max_to_keep=ckpt_cfg.max_to_keep,
            device=device
        )

        stopper = EarlyStopper(
            patience=train_cfg.patience,
            mode=train_cfg.metric_mode,
            min_delta=getattr(train_cfg, 'min_delta', 0.0)
        )

        notifier = NtfyNotifier(
            server_url = ntfy_cfg.server_url,
            topic = ntfy_cfg.topic,
        ) if ntfy_cfg.enabled else None

        # è°ƒç”¨æ ‡å‡†æž„é€ å‡½æ•°
        return cls(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            device=device,
            checkpoint_manager=ckpt_mgr,
            early_stopper=stopper,
            notifier=notifier,
            scheduler=scheduler,
            use_amp=train_cfg.use_amp,
            grad_accum_steps=train_cfg.grad_accum_steps,
            max_grad_norm=getattr(train_cfg, 'max_grad_norm', None),
            metric_to_track=train_cfg.metric_to_track,
            metric_mode=train_cfg.metric_mode,
            compute_top5=getattr(train_cfg, 'compute_top5', False),
            log_interval=getattr(train_cfg, 'log_interval', 1),
            val_interval=getattr(train_cfg, 'val_interval', 1)
        )

    # ============================================================
    # å…¬å…±æ–¹æ³• - ä¸»è®­ç»ƒå¾ªçŽ¯
    # ============================================================

    def fit(
            self,
            train_loader: DataLoader,
            val_loader: Optional[DataLoader] = None,
            epochs: int = 100
    ) -> Dict[str, Any]:
        """
        ä¸»è®­ç»ƒå¾ªçŽ¯ã€‚

        å‚æ•°:
            train_loader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader (DataLoader, optional): éªŒè¯æ•°æ®åŠ è½½å™¨
            epochs (int): æ€»è®­ç»ƒè½®æ•° (é»˜è®¤: 100)

        è¿”å›ž:
            dict: è®­ç»ƒåŽ†å²å’Œæœ€ä½³æŒ‡æ ‡
        """
        total_start_time = time.monotonic()

        logger.info("=" * 70)
        logger.info(f"ðŸš€ å¼€å§‹è®­ç»ƒ: Epoch {self.start_epoch + 1} -> {epochs}".center(70))
        logger.info(f"   è·Ÿè¸ªæŒ‡æ ‡: '{self.metric_to_track}' (æ¨¡å¼: {self.metric_mode})".center(70))
        if self.early_stopper:
            logger.info(f"   æ—©åœè€å¿ƒ: {self.early_stopper.patience} epochs".center(70))
        log_memory_usage("è®­ç»ƒå¼€å§‹å‰")
        logger.info("=" * 70)

        if self.notifier:
            self.notifier.notify_start(
                f"è®­ç»ƒå¼€å§‹\n"
                f"Epochs: {self.start_epoch + 1} â†’ {epochs}\n"
                f"è·Ÿè¸ªæŒ‡æ ‡: {self.metric_to_track}"
            )

        try:
            for epoch in range(self.start_epoch, epochs):
                self.current_epoch = epoch
                epoch_start_time = time.monotonic()

                # ========== 1. è®­ç»ƒé˜¶æ®µ ==========
                train_metrics = self._train_epoch(train_loader)
                self._on_train_epoch_end(epoch, train_metrics)

                # ========== 2. éªŒè¯é˜¶æ®µ ==========
                val_metrics = {}
                if val_loader and (epoch % self.val_interval == 0 or epoch == epochs - 1):
                    val_metrics = self._eval_epoch(val_loader)
                    self._on_eval_epoch_end(epoch, val_metrics)

                # ========== 3. æ—¥å¿—è®°å½• ==========
                if epoch % self.log_interval == 0:
                    self._log_epoch_metrics(epoch, epochs, train_metrics, val_metrics, epoch_start_time)

                # è®°å½•åŽ†å²
                epoch_history = {
                    'epoch': epoch,
                    **{f'train_{k}': v for k, v in train_metrics.items()},
                    **{f'val_{k}': v for k, v in val_metrics.items()}
                }
                self.training_history.append(epoch_history)

                # ========== 4. å­¦ä¹ çŽ‡è°ƒåº¦ ==========
                self._step_scheduler(val_metrics)

                # ========== 5. æ£€æŸ¥ç‚¹ä¿å­˜ä¸Žæ—©åœ ==========
                should_stop = self._save_and_check_stop(epoch, val_metrics)
                if should_stop:
                    logger.warning(f"æ—©åœè§¦å‘ï¼Œè®­ç»ƒç»ˆæ­¢äºŽ Epoch {epoch + 1}")
                    break

        except KeyboardInterrupt:
            logger.critical(f"æ£€æµ‹åˆ°é”®ç›˜ä¸­æ–­ (Ctrl+C)ï¼Œè®­ç»ƒè¢«ä¸­æ–­äºŽ Epoch {self.current_epoch + 1}")
            self._handle_interrupt()
            if self.notifier:
                self.notifier.notify_error(
                    "è®­ç»ƒè¢«ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­",
                    "KeyboardInterrupt"
                )

        except Exception as e:
            logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•èŽ·çš„å¼‚å¸¸: {type(e).__name__}")
            error_details = traceback.format_exc()
            logger.exception(error_details)
            if self.notifier:
                self.notifier.notify_error(
                    f"è®­ç»ƒå¤±è´¥: {type(e).__name__}",
                    error_details
                )
            raise

        else:
            logger.success("=" * 70)
            logger.success(f"è®­ç»ƒåœ¨ Epoch {epochs} æ­£å¸¸å®Œæˆ")
            logger.success(f"æœ€ä½³æŒ‡æ ‡ ({self.metric_to_track}): {self.best_metric:.4f}")
            logger.success("=" * 70)

            if self.notifier:
                self.notifier.notify_success(
                    f"è®­ç»ƒå·²æ­£å¸¸å®Œæˆ\n\n"
                    f"**æ€»è½®æ•°:** {epochs}\n"
                    f"**æœ€ä½³æŒ‡æ ‡:** {self.best_metric:.4f}"
                )

        finally:
            total_duration = time.monotonic() - total_start_time
            logger.info(f"æ€»è®­ç»ƒè€—æ—¶: {format_time(total_duration)}")
            self._cleanup()

        return {
            'history': self.training_history,
            'best_metric': self.best_metric
        }

    # ============================================================
    # æ ¸å¿ƒç§æœ‰æ–¹æ³• - è®­ç»ƒå’Œè¯„ä¼°çš„ä¸€ä¸ª epoch
    # ============================================================

    def _train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ª epochã€‚

        å‚æ•°:
            train_loader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨

        è¿”å›ž:
            dict: åŒ…å«å¹³å‡æŒ‡æ ‡çš„å­—å…¸ (ä¾‹å¦‚ {'loss': 0.123, 'acc': 95.2})
        """
        self.model.train()

        self.metric_tracker.reset()
        self.lr_meter.reset()

        with Progress(
                train_loader,
                description=f"Epoch {self.current_epoch + 1} [Train]",
                device=self.device,
                leave=False
        ) as pbar:

            for step, batch in enumerate(pbar):
                # ========== 1. æ‰§è¡Œè®­ç»ƒæ­¥éª¤ ==========
                step_result = self._train_step(batch)

                loss = step_result['loss']
                outputs = step_result['outputs']
                targets = step_result['targets']

                # ========== 2. åå‘ä¼ æ’­ ==========
                scaled_loss = loss / self.grad_accum_steps

                if self.scaler.is_enabled():
                    self.scaler.scale(scaled_loss).backward()
                else:
                    scaled_loss.backward()

                # ========== 3. ä¼˜åŒ–å™¨æ›´æ–° ==========
                if (step + 1) % self.grad_accum_steps == 0:
                    if self.max_grad_norm is not None:
                        if self.scaler.is_enabled():
                            self.scaler.unscale_(self.optimizer)
                        torch.nn.utils.clip_grad_norm_(
                            self.model.parameters(),
                            self.max_grad_norm
                        )

                    if self.scaler.is_enabled():
                        self.scaler.step(self.optimizer)
                        self.scaler.update()
                    else:
                        self.optimizer.step()

                    self.optimizer.zero_grad(set_to_none=True)
                    self.global_step += 1

                # ========== 4. æŒ‡æ ‡è·Ÿè¸ª ==========
                self.metric_tracker.update(loss, outputs, targets)

                current_lr = self.optimizer.param_groups[0]['lr']
                self.lr_meter.update(current_lr)

                pbar.update({'loss': loss, 'lr': current_lr})

        # ========== 5. è®¡ç®—å¹³å‡æŒ‡æ ‡ ==========
        metrics = self.metric_tracker.compute()
        metrics['lr'] = self.lr_meter.avg
        return metrics

    def _eval_epoch(self, eval_loader: DataLoader) -> Dict[str, float]:
        """
        è¯„ä¼°ä¸€ä¸ª epochã€‚

        å‚æ•°:
            eval_loader (DataLoader): è¯„ä¼°æ•°æ®åŠ è½½å™¨

        è¿”å›ž:
            dict: åŒ…å«å¹³å‡æŒ‡æ ‡çš„å­—å…¸
        """
        self.model.eval()

        self.metric_tracker.reset()

        with Progress(
                eval_loader,
                description=f"Epoch {self.current_epoch + 1} [Eval]",
                device=self.device,
                leave=False
        ) as pbar:

            with torch.no_grad():
                for batch in pbar:
                    # ========== 1. æ‰§è¡Œè¯„ä¼°æ­¥éª¤ ==========
                    step_result = self._eval_step(batch)

                    loss = step_result['loss']
                    outputs = step_result['outputs']
                    targets = step_result['targets']

                    # ========== 2. æŒ‡æ ‡è·Ÿè¸ª ==========
                    self.metric_tracker.update(loss, outputs, targets)
                    pbar.update({'loss': loss})

        # ========== 3. è®¡ç®—å¹³å‡æŒ‡æ ‡ ==========
        return self.metric_tracker.compute()

    # ============================================================
    # å¯é‡å†™çš„ä¿æŠ¤æ–¹æ³• - ä¾›å­ç±»å®šåˆ¶
    # ============================================================

    def _train_step(self, batch) -> Dict[str, torch.Tensor]:
        """
        (å¯é‡å†™) å•ä¸ªè®­ç»ƒæ­¥éª¤ã€‚

        é»˜è®¤å®žçŽ°: æ ‡å‡†çš„åˆ†ç±»ä»»åŠ¡
            - è¾“å…¥: (images, labels)
            - è¾“å‡º: logits
            - æŸå¤±: criterion(logits, labels)

        å­ç±»å¯ä»¥é‡å†™ä»¥æ”¯æŒ:
            - å¤šä»»åŠ¡å­¦ä¹  (å¤šä¸ªè¾“å‡ºå’ŒæŸå¤±)
            - GAN è®­ç»ƒ (ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨)
            - å¯¹æ¯”å­¦ä¹ 
            - è‡ªç›‘ç£å­¦ä¹ 

        å‚æ•°:
            batch: æ¥è‡ª DataLoader çš„ä¸€ä¸ªæ‰¹æ¬¡ (é€šå¸¸æ˜¯ (inputs, targets))

        è¿”å›ž:
            dict: å¿…é¡»åŒ…å«ä»¥ä¸‹é”®
                - 'loss' (Tensor): å½“å‰ batch çš„æŸå¤± (æ ‡é‡)
                - 'outputs' (Tensor): æ¨¡åž‹è¾“å‡ºçš„ logits (shape: [batch, num_classes])
                - 'targets' (Tensor): çœŸå®žæ ‡ç­¾ (shape: [batch])

        ç¤ºä¾‹ (å¤šä»»åŠ¡å­¦ä¹ ):
            def _train_step(self, batch):
                inputs, target_cls, target_seg = batch
                inputs = inputs.to(self.device, non_blocking=True)
                target_cls = target_cls.to(self.device, non_blocking=True)
                target_seg = target_seg.to(self.device, non_blocking=True)

                with autocast(self.device.type, enabled=self.scaler.is_enabled()):
                    out_cls, out_seg = self.model(inputs)
                    loss_cls = self.criterion[0](out_cls, target_cls)
                    loss_seg = self.criterion[1](out_seg, target_seg)
                    total_loss = loss_cls + 0.5 * loss_seg

                return {
                    'loss': total_loss,
                    'outputs': out_cls,
                    'targets': target_cls
                }
        """
        inputs, targets = batch

        inputs = inputs.to(self.device, non_blocking=True)
        targets = targets.to(self.device, non_blocking=True)

        with autocast(self.device.type, enabled=self.scaler.is_enabled()):
            outputs = self.model(inputs)
            loss = self.criterion(outputs, targets)

        return {
            'loss': loss,
            'outputs': outputs,
            'targets': targets
        }

    def _eval_step(self, batch) -> Dict[str, torch.Tensor]:
        """
        (å¯é‡å†™) å•ä¸ªè¯„ä¼°æ­¥éª¤ã€‚

        é»˜è®¤å®žçŽ°: ä¸Ž _train_step ç›¸åŒçš„é€»è¾‘ (ä½†åœ¨ eval æ¨¡å¼å’Œ no_grad ä¸‹)

        å‚æ•°:
            batch: æ¥è‡ª DataLoader çš„ä¸€ä¸ªæ‰¹æ¬¡

        è¿”å›ž:
            dict: ä¸Ž _train_step ç›¸åŒçš„æ ¼å¼
        """
        inputs, targets = batch

        inputs = inputs.to(self.device, non_blocking=True)
        targets = targets.to(self.device, non_blocking=True)

        with autocast(self.device.type, enabled=self.scaler.is_enabled()):
            outputs = self.model(inputs)
            loss = self.criterion(outputs, targets)

        return {
            'loss': loss,
            'outputs': outputs,
            'targets': targets
        }

    def _on_train_epoch_end(self, epoch: int, train_metrics: Dict[str, float]):
        """
        (å¯é‡å†™) è®­ç»ƒ epoch ç»“æŸæ—¶çš„é’©å­ã€‚

        ç”¨é€”:
            - è®°å½•é¢å¤–çš„ä¿¡æ¯ (ä¾‹å¦‚æƒé‡ç›´æ–¹å›¾)
            - æ‰§è¡Œè‡ªå®šä¹‰çš„é€»è¾‘ (ä¾‹å¦‚æ›´æ–°å¯è§†åŒ–)

        å‚æ•°:
            epoch (int): å½“å‰ epoch ç¼–å·
            train_metrics (dict): è®­ç»ƒæŒ‡æ ‡
        """
        pass

    def _on_eval_epoch_end(self, epoch: int, val_metrics: Dict[str, float]):
        """
        (å¯é‡å†™) è¯„ä¼° epoch ç»“æŸæ—¶çš„é’©å­ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch ç¼–å·
            val_metrics (dict): éªŒè¯æŒ‡æ ‡
        """
        pass

    # ============================================================
    # è¾…åŠ©ç§æœ‰æ–¹æ³• - æ£€æŸ¥ç‚¹ã€æ—©åœã€å­¦ä¹ çŽ‡è°ƒåº¦ç­‰
    # ============================================================

    def _save_and_check_stop(
            self,
            epoch: int,
            val_metrics: Dict[str, float]
    ) -> bool:
        """
        å°è£…æ£€æŸ¥ç‚¹ä¿å­˜å’Œæ—©åœé€»è¾‘ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch
            val_metrics (dict): éªŒè¯æŒ‡æ ‡

        è¿”å›ž:
            bool: æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ
        """
        if not self.checkpoint_manager and not self.early_stopper:
            return False

        is_best = False
        should_stop = False

        # æž„å»ºçŠ¶æ€å­—å…¸
        state = self._build_checkpoint_state(epoch, val_metrics)
        self.interrupt_state = state

        # ä¿å­˜æ»šåŠ¨æ£€æŸ¥ç‚¹
        if self.checkpoint_manager:
            self.checkpoint_manager.save_epoch_checkpoint(state, epoch)

        # æ—©åœä¸Žæœ€ä½³æ¨¡åž‹
        if self.early_stopper and val_metrics:
            current_metric = val_metrics.get(self.metric_to_track)

            if current_metric is not None:
                is_best = self.early_stopper.step(current_metric)

                if is_best:
                    self.best_metric = self.early_stopper.best_metric
                    if self.checkpoint_manager:
                        logger.success(
                            f"Epoch {epoch + 1}: å‘çŽ°æ–°çš„æœ€ä½³æ¨¡åž‹ï¼Œ"
                            f"{self.metric_to_track}={self.best_metric:.4f}"
                        )
                        self.checkpoint_manager.save_best_model(state, self.best_metric)

                should_stop = self.early_stopper.should_stop

        return should_stop

    def _load_checkpoint(self):
        """
        ä»Žæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚
        """
        logger.info("å°è¯•ä»Žæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ...")

        checkpoint = self.checkpoint_manager.load_latest_checkpoint()

        if checkpoint is None:
            logger.info("æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œä»Žå¤´å¼€å§‹è®­ç»ƒ")
            return

        try:
            self.model.load_state_dict(checkpoint['model_state'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state'])

            self.start_epoch = checkpoint['epoch'] + 1
            self.global_step = checkpoint.get('global_step', 0)

            if self.scheduler and 'scheduler_state' in checkpoint:
                self.scheduler.load_state_dict(checkpoint['scheduler_state'])
                logger.debug("å­¦ä¹ çŽ‡è°ƒåº¦å™¨çŠ¶æ€å·²æ¢å¤")

            if self.early_stopper and 'early_stopper_state' in checkpoint:
                self.early_stopper.load_state_dict(checkpoint['early_stopper_state'])
                logger.debug("æ—©åœå™¨çŠ¶æ€å·²æ¢å¤")

            if self.scaler.is_enabled() and 'scaler_state' in checkpoint:
                self.scaler.load_state_dict(checkpoint['scaler_state'])
                logger.debug("GradScaler çŠ¶æ€å·²æ¢å¤")

            if 'best_metric' in checkpoint:
                self.best_metric = checkpoint['best_metric']

            if 'training_history' in checkpoint:
                self.training_history = checkpoint['training_history']

            logger.success(f"è®­ç»ƒå·²ä»Ž Epoch {self.start_epoch} æ¢å¤")

        except Exception as e:
            logger.error(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}ï¼Œå°†ä»Žå¤´å¼€å§‹è®­ç»ƒ")
            self.start_epoch = 0

    def _build_checkpoint_state(
            self,
            epoch: int,
            val_metrics: Dict[str, float]
    ) -> Dict[str, Any]:
        """
        æž„å»ºæ£€æŸ¥ç‚¹çŠ¶æ€å­—å…¸ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch
            val_metrics (dict): éªŒè¯æŒ‡æ ‡

        è¿”å›ž:
            dict: å®Œæ•´çš„çŠ¶æ€å­—å…¸
        """
        state = {
            'epoch': epoch,
            'global_step': self.global_step,
            'model_state': self.model.state_dict(),
            'optimizer_state': self.optimizer.state_dict(),
            'best_metric': self.best_metric,
            'training_history': self.training_history
        }

        if val_metrics:
            state['val_metrics'] = val_metrics

        if self.scheduler:
            state['scheduler_state'] = self.scheduler.state_dict()

        if self.early_stopper:
            state['early_stopper_state'] = self.early_stopper.state_dict()

        if self.scaler.is_enabled():
            state['scaler_state'] = self.scaler.state_dict()

        return state

    def _step_scheduler(self, val_metrics: Dict[str, float]):
        """
        æ‰§è¡Œå­¦ä¹ çŽ‡è°ƒåº¦å™¨æ­¥éª¤ã€‚

        å‚æ•°:
            val_metrics (dict): éªŒè¯æŒ‡æ ‡
        """
        if not self.scheduler:
            return

        scheduler_name = type(self.scheduler).__name__

        if scheduler_name == 'ReduceLROnPlateau':
            metric_val = val_metrics.get(self.metric_to_track)
            if metric_val is not None:
                self.scheduler.step(metric_val)
            else:
                logger.warning("ReduceLROnPlateau éœ€è¦éªŒè¯æŒ‡æ ‡ï¼Œä½†æœªæä¾›")
        else:
            self.scheduler.step()

    def _handle_interrupt(self):
        """
        å¤„ç†è®­ç»ƒä¸­æ–­ (Ctrl+C)ã€‚
        """
        if self.checkpoint_manager and self.interrupt_state:
            logger.warning("æ­£åœ¨ä¿å­˜ä¸­æ–­æ£€æŸ¥ç‚¹...")
            self.checkpoint_manager.save_interrupt_checkpoint(self.interrupt_state)
            logger.success("ä¸­æ–­æ£€æŸ¥ç‚¹å·²ä¿å­˜")
        else:
            logger.warning("æœªé…ç½® CheckpointManager æˆ–çŠ¶æ€ä¸ºç©ºï¼Œä¸­æ–­æ£€æŸ¥ç‚¹æœªä¿å­˜")

    def _cleanup(self):
        """
        è®­ç»ƒç»“æŸåŽçš„èµ„æºæ¸…ç†ã€‚
        """
        log_memory_usage("è®­ç»ƒç»“æŸåŽ")
        if self.device.type == 'cuda':
            clear_memory()
            logger.debug("GPU ç¼“å­˜å·²æ¸…ç†")

    def _log_epoch_metrics(
            self,
            epoch: int,
            total_epochs: int,
            train_metrics: Dict[str, float],
            val_metrics: Dict[str, float],
            epoch_start_time: float
    ):
        """
        æ ¼å¼åŒ–å¹¶è®°å½•æŒ‡æ ‡åˆ°æ—¥å¿—ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch
            total_epochs (int): æ€» epoch æ•°
            train_metrics (dict): è®­ç»ƒæŒ‡æ ‡
            val_metrics (dict): éªŒè¯æŒ‡æ ‡
            epoch_start_time (float): epoch å¼€å§‹æ—¶é—´
        """
        duration = time.monotonic() - epoch_start_time

        msg_parts = [f"Epoch {epoch + 1:03d}/{total_epochs}"]
        msg_parts.append(f"Time: {format_time(duration)}")
        msg_parts.append(f"Loss: {train_metrics['loss']:.4f}")
        msg_parts.append(f"Acc: {train_metrics.get('acc', 0):.2f}%")

        if val_metrics:
            msg_parts.append(f"Val Loss: {val_metrics['loss']:.4f}")
            msg_parts.append(f"Val Acc: {val_metrics.get('acc', 0):.2f}%")

        if 'top5' in train_metrics:
            msg_parts.append(f"Top5: {train_metrics['top5']:.2f}%")

        msg_parts.append(f"LR: {train_metrics.get('lr', 0):.2e}")

        if self.device.type == 'cuda':
            mem_info = get_memory_usage()
            if mem_info:
                msg_parts.append(f"Mem: {mem_info['allocated']}")

        log_msg = " | ".join(msg_parts)
        logger.success(log_msg)

    # ============================================================
    # å®žç”¨æ–¹æ³• - ä¾›å¤–éƒ¨è°ƒç”¨
    # ============================================================

    def get_current_lr(self) -> float:
        """
        èŽ·å–å½“å‰å­¦ä¹ çŽ‡ã€‚

        è¿”å›ž:
            float: å½“å‰å­¦ä¹ çŽ‡
        """
        return self.optimizer.param_groups[0]['lr']

    def get_training_history(self) -> List[Dict[str, float]]:
        """
        èŽ·å–è®­ç»ƒåŽ†å²ã€‚

        è¿”å›ž:
            list: åŒ…å«æ‰€æœ‰è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡çš„åŽ†å²è®°å½•
        """
        return self.training_history

    def get_best_metric(self) -> float:
        """
        èŽ·å–æœ€ä½³æŒ‡æ ‡å€¼ã€‚

        è¿”å›ž:
            float: æœ€ä½³æŒ‡æ ‡å€¼
        """
        return self.best_metric

    def __repr__(self) -> str:
        return (
            f"Trainer(\n"
            f"  model={type(self.model).__name__},\n"
            f"  device={self.device},\n"
            f"  use_amp={self.use_amp},\n"
            f"  grad_accum_steps={self.grad_accum_steps},\n"
            f"  current_epoch={self.current_epoch},\n"
            f"  best_metric={self.best_metric:.4f}\n"
            f")"
        )