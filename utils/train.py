#!/usr/bin/python
# -*- coding:utf-8 -*-
"""
Created on 2025/11/03
@author  : William_Trouvaille
@function: è®­ç»ƒå¾ªçŽ¯æ¨¡æ¿ï¼ˆæœ€ç»ˆç‰ˆï¼‰
@detail: æä¾›å¯é€‰çš„ã€é«˜åº¦å¯å®šåˆ¶çš„ Trainer ç±»ï¼Œç”¨äºŽæ ‡å‡†çš„ PyTorch è®­ç»ƒæµç¨‹
         æ•´åˆäº†ä¾èµ–æ³¨å…¥æ¨¡å¼å’Œé…ç½®é©±åŠ¨æ¨¡å¼ï¼Œæ”¯æŒå®Œæ•´çš„æ€§èƒ½ä¼˜åŒ–å’Œå¥å£®æ€§ä¿éšœ
"""

import time
import traceback
from typing import Dict, Any, Optional, Union, Literal

import torch
import torch.nn as nn
from loguru import logger
from torch.cuda.amp import autocast, GradScaler
from torch.optim import Optimizer
from torch.optim.lr_scheduler import _LRScheduler, ReduceLROnPlateau
from torch.utils.data import DataLoader

# å¯¼å…¥æˆ‘ä»¬å·²æœ‰çš„å·¥å…·
from .checkpoint_manager import CheckpointManager
from .early_stopping import EarlyStopper
from .helpers import clear_memory, format_time, log_memory_usage
from .metrics import MetricTracker, AverageMeter
from .ntfy_notifier import NtfyNotifier
from .progress import Progress


class Trainer:
    """
    å¯é€‰çš„ã€å¯å¤ç”¨çš„ PyTorch è®­ç»ƒåè°ƒå™¨ (Coordinator)ã€‚

    è®¾è®¡ç†å¿µ:
        - èŒè´£åˆ†ç¦»: Trainer è´Ÿè´£"å¦‚ä½•è®­ç»ƒ"(How)ï¼Œmain.py è´Ÿè´£"è®­ç»ƒä»€ä¹ˆ"(What)
        - ä¾èµ–æ³¨å…¥: é€šè¿‡ __init__ æŽ¥æ”¶æ‰€æœ‰å·²å®žä¾‹åŒ–çš„å·¥å…·ï¼Œæœ€å¤§åŒ–çµæ´»æ€§
        - æ¨¡æ¿æ–¹æ³•: è®­ç»ƒé€»è¾‘å¯é€šè¿‡é‡å†™ _train_step ç­‰æ–¹æ³•æ¥å®šåˆ¶
        - æ€§èƒ½ä¼˜å…ˆ: é»˜è®¤é›†æˆé«˜æ€§èƒ½å·¥å…·ï¼ˆMetricTracker, Progress, AMPï¼‰
    """

    # ========================================================================
    # 1. åˆå§‹åŒ–ä¸Žæž„é€ 
    # ========================================================================

    def __init__(
            self,
            model: nn.Module,
            optimizer: Optimizer,
            criterion: nn.Module,
            device: Union[str, torch.device],

            # (å¯é€‰å·¥å…·) é€šè¿‡ä¾èµ–æ³¨å…¥ä¼ å…¥
            checkpoint_manager: Optional[CheckpointManager] = None,
            early_stopper: Optional[EarlyStopper] = None,
            notifier: Optional[NtfyNotifier] = None,
            scheduler: Optional[_LRScheduler] = None,

            # (æ€§èƒ½ä¼˜åŒ–) é…ç½®é€‰é¡¹
            use_amp: bool = False,
            grad_accum_steps: int = 1,
            max_grad_norm: Optional[float] = None,

            # (æŒ‡æ ‡ä¸Žæ—¥å¿—) é…ç½®é€‰é¡¹
            metric_to_track: str = 'acc',
            metric_mode: Literal['min', 'max'] = 'max',
            compute_top5: bool = False,
            log_interval: int = 1,
            val_interval: int = 1,

            # (æ–°å¢ž) è¿›åº¦æ¡é…ç½®
            show_progress: bool = True,
            progress_update_interval: float = 1.5
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨ï¼ˆä¾èµ–æ³¨å…¥æ¨¡å¼ï¼‰ã€‚

        å‚æ•°:
            model (nn.Module): PyTorch æ¨¡åž‹ï¼ˆåº”å·² .to(device)ï¼‰
            optimizer (Optimizer): PyTorch ä¼˜åŒ–å™¨
            criterion (nn.Module): æŸå¤±å‡½æ•°
            device (str | torch.device): è®¡ç®—è®¾å¤‡

            checkpoint_manager (CheckpointManager, optional): æ£€æŸ¥ç‚¹ç®¡ç†å™¨
            early_stopper (EarlyStopper, optional): æ—©åœå™¨
            notifier (NtfyNotifier, optional): Ntfy é€šçŸ¥å™¨
            scheduler (_LRScheduler, optional): å­¦ä¹ çŽ‡è°ƒåº¦å™¨

            use_amp (bool): æ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆé»˜è®¤: Falseï¼‰
            grad_accum_steps (int): æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆé»˜è®¤: 1ï¼‰
            max_grad_norm (float, optional): æ¢¯åº¦è£å‰ªçš„æœ€å¤§èŒƒæ•°ï¼ˆé»˜è®¤: Noneï¼‰

            metric_to_track (str): æ—©åœ/æœ€ä½³æ¨¡åž‹æ‰€è·Ÿè¸ªçš„æŒ‡æ ‡é”®ï¼ˆé»˜è®¤: 'acc'ï¼‰
            metric_mode (str): 'max' (å‡†ç¡®çŽ‡) æˆ– 'min' (æŸå¤±)ï¼ˆé»˜è®¤: 'max'ï¼‰
            compute_top5 (bool): æ˜¯å¦è®¡ç®— Top-5 å‡†ç¡®çŽ‡ï¼ˆé»˜è®¤: Falseï¼‰
            log_interval (int): æ¯éš”å¤šå°‘ä¸ª epoch è®°å½•ä¸€æ¬¡è¯¦ç»†æ—¥å¿—ï¼ˆé»˜è®¤: 1ï¼‰
            val_interval (int): æ¯éš”å¤šå°‘ä¸ª epoch éªŒè¯ä¸€æ¬¡ï¼ˆé»˜è®¤: 1ï¼‰

            show_progress (bool): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆé»˜è®¤: Trueï¼‰
            progress_update_interval (float): è¿›åº¦æ¡æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰ï¼ˆé»˜è®¤: 1.5ï¼‰
        """
        logger.info("Trainer åˆå§‹åŒ–...")

        # --- 1. æ ¸å¿ƒç»„ä»¶ ---
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion

        # è®¾å¤‡å¤„ç†
        if isinstance(device, str):
            device = torch.device(device)
        self.device = device

        self.scheduler = scheduler

        # --- 2. å¯é€‰å·¥å…·ï¼ˆé€šè¿‡ä¾èµ–æ³¨å…¥ï¼‰---
        self.checkpoint_manager = checkpoint_manager
        self.early_stopper = early_stopper
        self.notifier = notifier

        # --- 3. æ€§èƒ½ä¼˜åŒ–é…ç½® ---
        self.use_amp = use_amp
        self.grad_accum_steps = max(1, grad_accum_steps)
        self.max_grad_norm = max_grad_norm

        # åˆå§‹åŒ– GradScalerï¼ˆç”¨äºŽ AMPï¼‰
        self.scaler = GradScaler() if (use_amp and self.device.type == 'cuda') else None

        if self.scaler:
            logger.info("AMP (è‡ªåŠ¨æ··åˆç²¾åº¦) å·²å¯ç”¨")
        if self.grad_accum_steps > 1:
            logger.info(f"æ¢¯åº¦ç´¯ç§¯å·²å¯ç”¨ï¼Œç´¯ç§¯æ­¥æ•°: {self.grad_accum_steps}")
        if self.max_grad_norm is not None:
            logger.info(f"æ¢¯åº¦è£å‰ªå·²å¯ç”¨ï¼Œæœ€å¤§èŒƒæ•°: {self.max_grad_norm}")

        # --- 4. æŒ‡æ ‡ä¸Žæ—¥å¿—é…ç½® ---
        self.metric_to_track = metric_to_track
        self.metric_mode = metric_mode
        self.compute_top5 = compute_top5
        self.log_interval = max(1, log_interval)
        self.val_interval = max(1, val_interval)

        # --- 5. (æ–°å¢ž) è¿›åº¦æ¡é…ç½® ---
        self.show_progress = show_progress
        self.progress_update_interval = progress_update_interval

        if not self.show_progress:
            logger.info("è¿›åº¦æ¡å·²ç¦ç”¨")

        # --- 6. è‡ªåŠ¨å®žä¾‹åŒ–å†…éƒ¨å·¥å…· ---
        self.metric_tracker = MetricTracker(self.device, compute_top5=self.compute_top5)
        self.lr_meter = AverageMeter()

        # --- 7. å†…éƒ¨çŠ¶æ€ ---
        self.current_epoch = 0
        self.global_step = 0
        self.best_metric = -float('inf') if self.metric_mode == 'max' else float('inf')
        self.training_history = []
        self.start_epoch = 0

        # --- 8. è‡ªåŠ¨æ¢å¤æ£€æŸ¥ç‚¹ ---
        if self.checkpoint_manager:
            self._load_checkpoint()

        logger.success(f"Trainer åˆå§‹åŒ–å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")

    @classmethod
    def from_config(
            cls,
            model: nn.Module,
            optimizer: Optimizer,
            criterion: nn.Module,
            device: Union[str, torch.device],
            config: Any,
            scheduler: Optional[_LRScheduler] = None
    ) -> 'Trainer':
        """
        (å¯é€‰) é…ç½®é©±åŠ¨æ¨¡å¼ï¼šä»Ž config å¯¹è±¡è‡ªåŠ¨å®žä¾‹åŒ–æ‰€æœ‰å·¥å…·ã€‚

        å‚æ•°:
            model, optimizer, criterion, device, scheduler: (åŒ __init__)
            config (Any): å®Œæ•´é…ç½®å¯¹è±¡ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å­é…ç½®:

                config.training (å¿…éœ€):
                    - use_amp (bool): æ˜¯å¦å¯ç”¨ AMP
                    - grad_accum_steps (int): æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
                    - max_grad_norm (float | None): æ¢¯åº¦è£å‰ªèŒƒæ•°
                    - metric_to_track (str): è·Ÿè¸ªçš„æŒ‡æ ‡åç§°ï¼ˆå¦‚ 'acc', 'loss'ï¼‰
                    - metric_mode (str): 'max' æˆ– 'min'
                    - compute_top5 (bool): æ˜¯å¦è®¡ç®— Top-5 å‡†ç¡®çŽ‡
                    - log_interval (int): æ—¥å¿—è®°å½•é—´éš”ï¼ˆepochï¼‰
                    - val_interval (int): éªŒè¯é—´éš”ï¼ˆepochï¼‰
                    - patience (int): æ—©åœå®¹å¿åº¦ï¼ˆ>0 å¯ç”¨æ—©åœï¼‰
                    - show_progress (bool, optional): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
                    - progress_update_interval (float, optional): è¿›åº¦æ¡æ›´æ–°é—´éš”

                config.checkpoint (å¯é€‰):
                    - enabled (bool): æ˜¯å¦å¯ç”¨æ£€æŸ¥ç‚¹ä¿å­˜
                    - save_dir (str): æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
                    - max_to_keep (int): ä¿ç•™çš„æ£€æŸ¥ç‚¹æ•°é‡

                config.ntfy (å¯é€‰):
                    - enabled (bool): æ˜¯å¦å¯ç”¨é€šçŸ¥

        è¿”å›ž:
            Trainer: å·²é…ç½®çš„ Trainer å®žä¾‹

        ç¤ºä¾‹:
            config = load_config_from_yaml("config.yaml")
            trainer = Trainer.from_config(model, optimizer, criterion, device, config)
            trainer.fit(train_loader, val_loader)
        """
        logger.info("Trainer (from_config æ¨¡å¼) åˆå§‹åŒ–...")

        # --- 1. ä»Ž config è‡ªåŠ¨å®žä¾‹åŒ–æ‰€æœ‰ utils å·¥å…· ---

        # æ£€æŸ¥ç‚¹
        ckpt_mgr = None
        if hasattr(config, 'checkpoint') and config.checkpoint.enabled:
            ckpt_mgr = CheckpointManager(
                save_dir=config.checkpoint.save_dir,
                device=device,
                max_to_keep=config.checkpoint.get('max_to_keep', 3)
            )

        # æ—©åœ
        early_stop = None
        if hasattr(config, 'training') and config.training.get('patience', 0) > 0:
            early_stop = EarlyStopper(
                patience=config.training.patience,
                mode=config.training.get('metric_mode', 'max'),
            )

        # é€šçŸ¥
        notifier = None
        if hasattr(config, 'ntfy') and config.ntfy.get('enabled', False):
            notifier = NtfyNotifier()

        # --- 2. è°ƒç”¨æ ‡å‡†çš„ __init__ï¼ˆä¾èµ–æ³¨å…¥æ¨¡å¼ï¼‰---
        return cls(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            device=device,
            checkpoint_manager=ckpt_mgr,
            early_stopper=early_stop,
            notifier=notifier,
            scheduler=scheduler,
            use_amp=config.training.get('use_amp', False),
            grad_accum_steps=config.training.get('grad_accum_steps', 1),
            max_grad_norm=config.training.get('max_grad_norm', None),
            metric_to_track=config.training.get('metric_to_track', 'acc'),
            metric_mode=config.training.get('metric_mode', 'max'),
            compute_top5=config.training.get('compute_top5', False),
            log_interval=config.training.get('log_interval', 1),
            val_interval=config.training.get('val_interval', 1),
            show_progress=config.training.get('show_progress', True),
            progress_update_interval=config.training.get('progress_update_interval', 0.5)
        )

    # ========================================================================
    # 2. å…¬å…±æ–¹æ³• - ä¸»è®­ç»ƒå¾ªçŽ¯
    # ========================================================================

    def fit(
            self,
            train_loader: DataLoader,
            val_loader: Optional[DataLoader] = None,
            epochs: int = 100
    ) -> Dict[str, Any]:
        """
        ä¸»è®­ç»ƒå¾ªçŽ¯ã€‚è¿™æ˜¯å”¯ä¸€çš„å…¬å…±æ–¹æ³•ã€‚

        å‚æ•°:
            train_loader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader (DataLoader, optional): éªŒè¯æ•°æ®åŠ è½½å™¨
            epochs (int): æ€»è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: 100ï¼‰

        è¿”å›ž:
            dict: åŒ…å«è®­ç»ƒåŽ†å²å’Œæœ€ä½³æŒ‡æ ‡çš„å­—å…¸
                - 'history': æ¯ä¸ª epoch çš„æŒ‡æ ‡åˆ—è¡¨
                - 'best_metric': æœ€ä½³éªŒè¯æŒ‡æ ‡å€¼
        """
        total_start_time = time.monotonic()

        # è®¡ç®—å®žé™…è®­ç»ƒçš„è½®æ¬¡æ•°
        num_epochs_to_train = epochs - self.start_epoch

        logger.info("=" * 80)
        logger.info(f"ðŸš€ å¼€å§‹è®­ç»ƒ: Epoch {self.start_epoch + 1} -> {epochs}ï¼ˆå…± {num_epochs_to_train} è½®ï¼‰".center(80))
        logger.info(f"   è·Ÿè¸ªæŒ‡æ ‡: '{self.metric_to_track}' (æ¨¡å¼: {self.metric_mode})".center(80))
        if self.early_stopper:
            logger.info(f"   æ—©åœå®¹å¿: {self.early_stopper.patience} epochs".center(80))
        log_memory_usage("è®­ç»ƒå¼€å§‹å‰")
        logger.info("=" * 80)

        # å‘é€å¼€å§‹é€šçŸ¥
        if self.notifier:
            self.notifier.notify_start(
                f"è®­ç»ƒå¼€å§‹\nEpochs: {self.start_epoch + 1}..{epochs}\n"
                f"æŒ‡æ ‡: {self.metric_to_track} ({self.metric_mode})"
            )

        try:
            # --- ä¸»è®­ç»ƒå¾ªçŽ¯ ---
            self._main_training_loop(train_loader, val_loader, epochs)

        except KeyboardInterrupt:
            # --- å¤„ç† Ctrl+C ---
            logger.critical("æ£€æµ‹åˆ°é”®ç›˜ä¸­æ–­ (Ctrl+C)ï¼Œè®­ç»ƒè¢«ä¸­æ–­")
            self._handle_interrupt()
            if self.notifier:
                self.notifier.notify_error("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­", "KeyboardInterrupt")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œç¡®ä¿ç¨‹åºç›´æŽ¥é€€å‡ºè€Œä¸æ˜¯ç»§ç»­æ‰§è¡ŒåŽç»­æµç¨‹
            raise

        except Exception as e:
            # --- å¤„ç†å…¶ä»–å¼‚å¸¸ ---
            logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•èŽ·çš„å¼‚å¸¸: {type(e).__name__}")
            error_details = traceback.format_exc()
            logger.exception(error_details)
            if self.notifier:
                self.notifier.notify_error(f"è®­ç»ƒå¤±è´¥: {e}", error_details)
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®© main.py çŸ¥é“

        else:
            # --- å¦‚æžœè®­ç»ƒæ­£å¸¸å®Œæˆ ---
            logger.success("=" * 80)
            logger.success(f"è®­ç»ƒåœ¨ Epoch {epochs} æ­£å¸¸å®Œæˆ")
            logger.success(f"æœ€ä½³æŒ‡æ ‡ ({self.metric_to_track}): {self.best_metric:.4f}")
            logger.success("=" * 80)

            if self.notifier:
                self.notifier.notify_success(
                    f"è®­ç»ƒå·²æ­£å¸¸å®Œæˆ\n"
                    f"Epochs: {epochs}\n"
                    f"æœ€ä½³ {self.metric_to_track}: {self.best_metric:.4f}"
                )

        finally:
            # --- æœ€ç»ˆæ¸…ç† ---
            total_duration = time.monotonic() - total_start_time
            logger.info(f"æ€»è®­ç»ƒè€—æ—¶: {format_time(total_duration)}")
            self._cleanup()

        return {
            'history': self.training_history,
            'best_metric': self.best_metric
        }

    # ========================================================================
    # 3. æ ¸å¿ƒç§æœ‰æ–¹æ³• - è®­ç»ƒå’Œè¯„ä¼°çš„ä¸€ä¸ª epoch
    # ========================================================================

    def _main_training_loop(
            self,
            train_loader: DataLoader,
            val_loader: Optional[DataLoader],
            total_epochs: int
    ):
        """(ç§æœ‰) åŒ…å«ä¸» for å¾ªçŽ¯çš„å†…éƒ¨ç¼–æŽ’å™¨"""

        for epoch in range(self.start_epoch, total_epochs):
            self.current_epoch = epoch
            epoch_start_time = time.monotonic()

            # --- 1. è®­ç»ƒé˜¶æ®µ ---
            train_metrics = self._train_epoch(train_loader, epoch)

            # è°ƒç”¨é’©å­ï¼ˆä¾›å­ç±»æ‰©å±•ï¼‰
            self._on_train_epoch_end(epoch, train_metrics)

            # --- 2. éªŒè¯é˜¶æ®µ ---
            val_metrics = {}
            if val_loader and (epoch % self.val_interval == 0 or epoch == total_epochs - 1):
                val_metrics = self._eval_epoch(val_loader, epoch)

                # è°ƒç”¨é’©å­ï¼ˆä¾›å­ç±»æ‰©å±•ï¼‰
                self._on_eval_epoch_end(epoch, val_metrics)

            # --- 3. å­¦ä¹ çŽ‡è°ƒåº¦ ---
            if self.scheduler:
                self._step_scheduler(val_metrics)

            # --- 4. æ—¥å¿—è®°å½• ---
            if epoch % self.log_interval == 0:
                self._log_epoch_metrics(epoch, train_metrics, val_metrics, epoch_start_time)

            # --- 5. æ£€æŸ¥ç‚¹ä¿å­˜ä¸Žæ—©åœæ£€æŸ¥ ---
            should_stop = self._save_and_check_stop(epoch, val_metrics)
            if should_stop:
                logger.warning(f"æ—©åœè§¦å‘ï¼Œè®­ç»ƒç»ˆæ­¢äºŽ Epoch {epoch + 1}")
                break

    def _train_epoch(self, train_loader: DataLoader, epoch: int) -> Dict[str, float]:
        """
        (ç§æœ‰) è®­ç»ƒä¸€ä¸ª epochã€‚

        å‚æ•°:
            train_loader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨
            epoch (int): å½“å‰ epoch ç¼–å·

        è¿”å›ž:
            dict: åŒ…å«å¹³å‡æŒ‡æ ‡çš„å­—å…¸ï¼ˆä¾‹å¦‚ {'loss': 0.123, 'acc': 95.2}ï¼‰
        """
        self.model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼

        # é‡ç½®æŒ‡æ ‡è·Ÿè¸ªå™¨
        self.metric_tracker.reset()
        self.lr_meter.reset()

        # (å¯é€‰) ä½¿ç”¨ Progress åŒ…è£…æ•°æ®åŠ è½½å™¨
        if self.show_progress:
            loader_wrapper = Progress(
                train_loader,
                description=f"Epoch {epoch + 1} [Train]",
                leave=False,
                update_interval_sec=self.progress_update_interval,
                device=self.device
            )
        else:
            loader_wrapper = train_loader

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆå¦‚æžœæ˜¯ Progressï¼‰æˆ–ç›´æŽ¥è¿­ä»£
        if self.show_progress:
            with loader_wrapper as pbar:
                self._train_epoch_inner_loop(pbar)
        else:
            self._train_epoch_inner_loop(loader_wrapper)

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        metrics = self.metric_tracker.compute()
        metrics['lr'] = self.lr_meter.avg

        return metrics

    def _train_epoch_inner_loop(self, loader):
        """(ç§æœ‰) è®­ç»ƒ epoch çš„å†…éƒ¨å¾ªçŽ¯"""
        for step, batch in enumerate(loader):
            # ========== 1. æ‰§è¡Œè®­ç»ƒæ­¥éª¤ ==========
            step_result = self._train_step(batch)

            loss = step_result['loss']
            outputs = step_result['outputs']
            targets = step_result['targets']

            # ========== 2. åå‘ä¼ æ’­ ==========
            scaled_loss = loss / self.grad_accum_steps

            if self.scaler:
                self.scaler.scale(scaled_loss).backward()
            else:
                scaled_loss.backward()

            # ========== 3. ä¼˜åŒ–å™¨æ›´æ–° ==========
            if (step + 1) % self.grad_accum_steps == 0:
                # (å¯é€‰) æ¢¯åº¦è£å‰ª
                if self.max_grad_norm is not None:
                    if self.scaler:
                        self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.max_grad_norm
                    )

                # ä¼˜åŒ–å™¨æ­¥éª¤
                if self.scaler:
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    self.optimizer.step()

                # æ¸…ç©ºæ¢¯åº¦
                self.optimizer.zero_grad(set_to_none=True)

                # æ›´æ–°å…¨å±€æ­¥æ•°
                self.global_step += 1

            # ========== 4. æŒ‡æ ‡è·Ÿè¸ª ==========
            self.metric_tracker.update(loss, outputs, targets)

            current_lr = self.optimizer.param_groups[0]['lr']
            self.lr_meter.update(current_lr)

            # ========== 5. æ›´æ–°è¿›åº¦æ¡ ==========
            if self.show_progress and hasattr(loader, 'update'):
                loader.update({'loss': loss, 'lr': current_lr})

    def _eval_epoch(self, eval_loader: DataLoader, epoch: int) -> Dict[str, float]:
        """
        (ç§æœ‰) è¯„ä¼°ä¸€ä¸ª epochã€‚

        å‚æ•°:
            eval_loader (DataLoader): è¯„ä¼°æ•°æ®åŠ è½½å™¨
            epoch (int): å½“å‰ epoch ç¼–å·

        è¿”å›ž:
            dict: åŒ…å«å¹³å‡æŒ‡æ ‡çš„å­—å…¸
        """
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        # é‡ç½®æŒ‡æ ‡è·Ÿè¸ªå™¨
        self.metric_tracker.reset()

        # (å¯é€‰) ä½¿ç”¨ Progress åŒ…è£…æ•°æ®åŠ è½½å™¨
        if self.show_progress:
            loader_wrapper = Progress(
                eval_loader,
                description=f"Epoch {epoch + 1} [Val]",
                leave=False,
                update_interval_sec=self.progress_update_interval,
                device=self.device
            )
        else:
            loader_wrapper = eval_loader

        # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        with torch.no_grad():
            if self.show_progress:
                with loader_wrapper as pbar:
                    self._eval_epoch_inner_loop(pbar)
            else:
                self._eval_epoch_inner_loop(loader_wrapper)

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        metrics = self.metric_tracker.compute()

        return metrics

    def _eval_epoch_inner_loop(self, loader):
        """(ç§æœ‰) è¯„ä¼° epoch çš„å†…éƒ¨å¾ªçŽ¯"""
        for batch in loader:
            # ========== 1. æ‰§è¡Œè¯„ä¼°æ­¥éª¤ ==========
            step_result = self._eval_step(batch)

            loss = step_result['loss']
            outputs = step_result['outputs']
            targets = step_result['targets']

            # ========== 2. æŒ‡æ ‡è·Ÿè¸ª ==========
            self.metric_tracker.update(loss, outputs, targets)

            # ========== 3. æ›´æ–°è¿›åº¦æ¡ ==========
            if self.show_progress and hasattr(loader, 'update'):
                loader.update({'loss': loss})

    # ========================================================================
    # 4. (å…³é”®) å¯é‡å†™çš„ä¿æŠ¤æ–¹æ³• - ä¾›å­ç±»å®šåˆ¶
    # ========================================================================

    def _train_step(self, batch) -> Dict[str, torch.Tensor]:
        """
        (å¯é‡å†™) å•ä¸ªè®­ç»ƒæ­¥éª¤ã€‚

        é»˜è®¤å®žçŽ°: æ ‡å‡†çš„åˆ†ç±»ä»»åŠ¡
            - è¾“å…¥: (images, labels)
            - è¾“å‡º: logits
            - æŸå¤±: criterion(logits, labels)

        å­ç±»å¯ä»¥é‡å†™ä»¥æ”¯æŒ:
            - å¤šä»»åŠ¡å­¦ä¹ ï¼ˆå¤šä¸ªè¾“å‡ºå’ŒæŸå¤±ï¼‰
            - GAN è®­ç»ƒï¼ˆç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼‰
            - å¯¹æ¯”å­¦ä¹ ï¼ˆSimCLR, MoCo ç­‰ï¼‰
            ç­‰ç­‰

        å‚æ•°:
            batch: æ¥è‡ª DataLoader çš„ä¸€ä¸ªæ‰¹æ¬¡ï¼ˆé€šå¸¸æ˜¯ (inputs, targets)ï¼‰

        è¿”å›ž:
            dict: å¿…é¡»åŒ…å«ä»¥ä¸‹é”®
                - 'loss' (Tensor): å½“å‰ batch çš„æŸå¤±ï¼ˆæ ‡é‡ï¼‰
                - 'outputs' (Tensor): æ¨¡åž‹è¾“å‡ºçš„ logits (shape: [batch, num_classes])
                - 'targets' (Tensor): çœŸå®žæ ‡ç­¾ (shape: [batch])

        ç¤ºä¾‹ï¼ˆå¤šä»»åŠ¡å­¦ä¹ ï¼‰:
            def _train_step(self, batch):
                inputs, target_cls, target_seg = batch
                inputs = inputs.to(self.device, non_blocking=True)
                target_cls = target_cls.to(self.device, non_blocking=True)
                target_seg = target_seg.to(self.device, non_blocking=True)

                with autocast('cuda', enabled=(self.scaler is not None)):
                    out_cls, out_seg = self.model(inputs)
                    loss_cls = self.criterion[0](out_cls, target_cls)
                    loss_seg = self.criterion[1](out_seg, target_seg)
                    total_loss = loss_cls + 0.5 * loss_seg

                return {
                    'loss': total_loss,
                    'outputs': out_cls,
                    'targets': target_cls
                }
        """
        # è§£åŒ… batchï¼ˆå‡è®¾æ˜¯æ ‡å‡†çš„ (inputs, targets)ï¼‰
        inputs, targets = batch

        # ç§»åˆ°è®¾å¤‡ï¼ˆä½¿ç”¨ non_blocking ä¼˜åŒ–ï¼‰
        inputs = inputs.to(self.device, non_blocking=True)
        targets = targets.to(self.device, non_blocking=True)

        # å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨ autocast æ”¯æŒ AMPï¼‰
        # æ³¨æ„ï¼šautocast ä»…åœ¨ CUDA è®¾å¤‡ä¸Šå¯ç”¨
        if self.scaler is not None:
            with autocast():
                outputs = self.model(inputs)
                loss = self.criterion(outputs, targets)
        else:
            outputs = self.model(inputs)
            loss = self.criterion(outputs, targets)

        return {
            'loss': loss,
            'outputs': outputs,
            'targets': targets
        }

    def _eval_step(self, batch) -> Dict[str, torch.Tensor]:
        """
        (å¯é‡å†™) å•ä¸ªè¯„ä¼°æ­¥éª¤ã€‚

        é»˜è®¤å®žçŽ°: ä¸Ž _train_step ç›¸åŒçš„é€»è¾‘ï¼ˆä½†åœ¨ eval æ¨¡å¼å’Œ no_grad ä¸‹ï¼‰

        å‚æ•°:
            batch: æ¥è‡ª DataLoader çš„ä¸€ä¸ªæ‰¹æ¬¡

        è¿”å›ž:
            dict: ä¸Ž _train_step ç›¸åŒçš„æ ¼å¼
        """
        # é»˜è®¤å®žçŽ°ï¼šä¸Žè®­ç»ƒæ­¥éª¤ç›¸åŒï¼ˆä½†å·²åœ¨ no_grad å’Œ eval æ¨¡å¼ä¸‹ï¼‰
        inputs, targets = batch

        inputs = inputs.to(self.device, non_blocking=True)
        targets = targets.to(self.device, non_blocking=True)

        # è¯„ä¼°æ—¶ä¹Ÿå¯ä»¥ä½¿ç”¨ AMPï¼ˆåŠ é€ŸæŽ¨ç†ï¼‰
        if self.scaler is not None:
            with autocast():
                outputs = self.model(inputs)
                loss = self.criterion(outputs, targets)
        else:
            outputs = self.model(inputs)
            loss = self.criterion(outputs, targets)

        return {
            'loss': loss,
            'outputs': outputs,
            'targets': targets
        }

    def _on_train_epoch_end(self, epoch: int, train_metrics: Dict[str, float]):
        """
        (å¯é‡å†™) è®­ç»ƒ epoch ç»“æŸæ—¶çš„é’©å­ã€‚

        ç”¨é€”:
            - è®°å½•é¢å¤–çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚æƒé‡ç›´æ–¹å›¾ï¼‰
            - æ‰§è¡Œè‡ªå®šä¹‰çš„é€»è¾‘ï¼ˆä¾‹å¦‚æ›´æ–°å¯è§†åŒ–ï¼‰

        å‚æ•°:
            epoch (int): å½“å‰ epoch ç¼–å·
            train_metrics (dict): è®­ç»ƒæŒ‡æ ‡
        """
        pass  # é»˜è®¤å®žçŽ°ï¼šä»€ä¹ˆéƒ½ä¸åš

    def _on_eval_epoch_end(self, epoch: int, val_metrics: Dict[str, float]):
        """
        (å¯é‡å†™) è¯„ä¼° epoch ç»“æŸæ—¶çš„é’©å­ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch ç¼–å·
            val_metrics (dict): éªŒè¯æŒ‡æ ‡
        """
        pass  # é»˜è®¤å®žçŽ°ï¼šä»€ä¹ˆéƒ½ä¸åš

    # ========================================================================
    # 5. è¾…åŠ©ç§æœ‰æ–¹æ³• - æ£€æŸ¥ç‚¹ã€æ—©åœã€å­¦ä¹ çŽ‡è°ƒåº¦ç­‰
    # ========================================================================

    def _save_and_check_stop(
            self,
            epoch: int,
            val_metrics: Dict[str, float]
    ) -> bool:
        """
        (ç§æœ‰) å°è£…æ£€æŸ¥ç‚¹ä¿å­˜å’Œæ—©åœé€»è¾‘ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch
            val_metrics (dict): éªŒè¯æŒ‡æ ‡

        è¿”å›ž:
            bool: True è¡¨ç¤ºåº”è¯¥åœæ­¢è®­ç»ƒ
        """
        if not self.checkpoint_manager and not self.early_stopper:
            return False  # æ²¡æœ‰å·¥å…·ï¼Œä»€ä¹ˆéƒ½ä¸åš

        # is_best = False

        # --- 1. å‡†å¤‡ state å­—å…¸ ---
        state = self._build_checkpoint_state(epoch, val_metrics)

        # --- 2. ä¿å­˜æ»šåŠ¨æ£€æŸ¥ç‚¹ ---
        if self.checkpoint_manager:
            self.checkpoint_manager.save_epoch_checkpoint(state, epoch)

        # --- 3. æ—©åœä¸Žæœ€ä½³æ¨¡åž‹ ---
        should_stop = False
        if self.early_stopper and val_metrics:
            current_metric = val_metrics.get(self.metric_to_track)

            if current_metric is None:
                logger.warning(
                    f"éªŒè¯æŒ‡æ ‡ä¸­æœªæ‰¾åˆ° '{self.metric_to_track}'ï¼Œè·³è¿‡æ—©åœæ£€æŸ¥ã€‚"
                    f"å¯ç”¨æŒ‡æ ‡: {list(val_metrics.keys())}"
                )
            else:
                # (å…³é”®) is_best ç”± EarlyStopper è¿”å›ž
                is_best = self.early_stopper.step(current_metric)

                if is_best:
                    self.best_metric = current_metric
                    if self.checkpoint_manager:
                        logger.success(
                            f"Epoch {epoch + 1}: å‘çŽ°æ–°çš„æœ€ä½³æ¨¡åž‹ï¼"
                            f"{self.metric_to_track} = {self.best_metric:.4f}"
                        )
                        self.checkpoint_manager.save_best_model(state, self.best_metric)

                should_stop = self.early_stopper.should_stop

        return should_stop

    def _load_checkpoint(self):
        """(ç§æœ‰) ä»Žæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ"""
        logger.info("å°è¯•ä»Žæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ...")

        checkpoint = self.checkpoint_manager.load_latest_checkpoint()

        if checkpoint is None:
            logger.info("æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œä»Žå¤´å¼€å§‹è®­ç»ƒ")
            return

        try:
            # æ¢å¤æ¨¡åž‹å’Œä¼˜åŒ–å™¨
            self.model.load_state_dict(checkpoint['model_state'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state'])

            # æ¢å¤ epoch
            self.start_epoch = checkpoint['epoch'] + 1

            # (å¯é€‰) æ¢å¤ scheduler
            if self.scheduler and 'scheduler_state' in checkpoint:
                self.scheduler.load_state_dict(checkpoint['scheduler_state'])
                logger.debug("å­¦ä¹ çŽ‡è°ƒåº¦å™¨çŠ¶æ€å·²æ¢å¤")

            # (å¯é€‰) æ¢å¤æ—©åœå™¨
            if self.early_stopper and 'early_stopper_state' in checkpoint:
                self.early_stopper.load_state_dict(checkpoint['early_stopper_state'])
                logger.debug("æ—©åœå™¨çŠ¶æ€å·²æ¢å¤")

            # (å¯é€‰) æ¢å¤ scaler (AMP)
            if self.scaler and 'scaler_state' in checkpoint:
                self.scaler.load_state_dict(checkpoint['scaler_state'])
                logger.debug("GradScaler çŠ¶æ€å·²æ¢å¤")

            # (å¯é€‰) æ¢å¤æœ€ä½³æŒ‡æ ‡
            if 'best_metric' in checkpoint:
                self.best_metric = checkpoint['best_metric']

            # (å¯é€‰) æ¢å¤è®­ç»ƒåŽ†å²
            if 'history' in checkpoint:
                self.training_history = checkpoint['history']

            logger.success(f"è®­ç»ƒå·²ä»Ž Epoch {self.start_epoch} æ¢å¤")
            logger.info(f"å·²æ¢å¤çš„æœ€ä½³æŒ‡æ ‡ ({self.metric_to_track}): {self.best_metric:.4f}")
            logger.info(f"æç¤º: è®­ç»ƒå°†ä»Ž Epoch {self.start_epoch + 1} ç»§ç»­ï¼Œè¯·åœ¨ fit() ä¸­æŒ‡å®šç›®æ ‡ epoch æ•°")

        except Exception as e:
            logger.error(f"åŠ è½½æ£€æŸ¥ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            logger.warning("å°†ä»Žå¤´å¼€å§‹è®­ç»ƒ")
            self.start_epoch = 0

    def _build_checkpoint_state(
            self,
            epoch: int,
            val_metrics: Dict[str, float]
    ) -> Dict[str, Any]:
        """
        (ç§æœ‰) æž„å»ºæ£€æŸ¥ç‚¹çŠ¶æ€å­—å…¸ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch
            val_metrics (dict): éªŒè¯æŒ‡æ ‡

        è¿”å›ž:
            dict: å®Œæ•´çš„çŠ¶æ€å­—å…¸
        """
        state = {
            'epoch': epoch,
            'global_step': self.global_step,
            'model_state': self.model.state_dict(),
            'optimizer_state': self.optimizer.state_dict(),
            'best_metric': self.best_metric,
            'history': self.training_history
        }

        # (å¯é€‰) æ·»åŠ éªŒè¯æŒ‡æ ‡
        if val_metrics:
            state['val_metrics'] = val_metrics

        # (å¯é€‰) ä¿å­˜ scheduler çŠ¶æ€
        if self.scheduler:
            state['scheduler_state'] = self.scheduler.state_dict()

        # (å¯é€‰) ä¿å­˜æ—©åœå™¨çŠ¶æ€
        if self.early_stopper:
            state['early_stopper_state'] = self.early_stopper.state_dict()

        # (å¯é€‰) ä¿å­˜ scaler çŠ¶æ€ï¼ˆAMPï¼‰
        if self.scaler:
            state['scaler_state'] = self.scaler.state_dict()

        return state

    def _step_scheduler(self, val_metrics: Dict[str, float]):
        """
        (ç§æœ‰) æ‰§è¡Œå­¦ä¹ çŽ‡è°ƒåº¦å™¨æ­¥éª¤ã€‚

        å‚æ•°:
            val_metrics (dict): éªŒè¯æŒ‡æ ‡
        """
        # åˆ¤æ–­ scheduler çš„ç±»åž‹
        if isinstance(self.scheduler, ReduceLROnPlateau):
            # ReduceLROnPlateau éœ€è¦ä¼ å…¥æŒ‡æ ‡
            metric_value = val_metrics.get(self.metric_to_track)
            if metric_value is None:
                logger.warning(
                    f"ReduceLROnPlateau éœ€è¦éªŒè¯æŒ‡æ ‡ '{self.metric_to_track}'ï¼Œä½†æœªæ‰¾åˆ°"
                )
            else:
                self.scheduler.step(metric_value)
        else:
            # å…¶ä»– schedulerï¼ˆå¦‚ StepLR, CosineAnnealingLRï¼‰
            self.scheduler.step()

    def _handle_interrupt(self):
        """
        (ç§æœ‰) å¤„ç†è®­ç»ƒä¸­æ–­ï¼ˆCtrl+Cï¼‰ã€‚
        """
        if self.checkpoint_manager:
            logger.warning("æ­£åœ¨ä¿å­˜ä¸­æ–­æ£€æŸ¥ç‚¹...")

            state = self._build_checkpoint_state(self.current_epoch, {})

            self.checkpoint_manager.save_interrupt_checkpoint(state)
            logger.success("ä¸­æ–­æ£€æŸ¥ç‚¹å·²ä¿å­˜")
        else:
            logger.warning("æœªé…ç½® CheckpointManagerï¼Œä¸­æ–­æ£€æŸ¥ç‚¹æœªä¿å­˜")

    def _cleanup(self):
        """
        (ç§æœ‰) è®­ç»ƒç»“æŸåŽçš„èµ„æºæ¸…ç†ã€‚
        """
        # æ¸…ç† GPU ç¼“å­˜
        if self.device.type == 'cuda':
            clear_memory()
            logger.debug("GPU ç¼“å­˜å·²æ¸…ç†")

    def _log_epoch_metrics(
            self,
            epoch: int,
            train_metrics: Dict[str, float],
            val_metrics: Dict[str, float],
            epoch_start_time: float
    ):
        """
        (ç§æœ‰) æ ¼å¼åŒ–å¹¶è®°å½• epoch æŒ‡æ ‡åˆ°æ—¥å¿—ã€‚

        å‚æ•°:
            epoch (int): å½“å‰ epoch
            train_metrics (dict): è®­ç»ƒæŒ‡æ ‡
            val_metrics (dict): éªŒè¯æŒ‡æ ‡
            epoch_start_time (float): epoch å¼€å§‹æ—¶é—´
        """
        duration = time.monotonic() - epoch_start_time

        # æž„å»ºæ—¥å¿—æ¶ˆæ¯
        msg_parts = [f"Epoch {epoch + 1:03d}"]
        msg_parts.append(f"Time: {format_time(duration)}")
        msg_parts.append(f"Train Loss: {train_metrics.get('loss', 0):.4f}")
        msg_parts.append(f"Train Acc: {train_metrics.get('acc', 0):.2f}%")

        if val_metrics:
            msg_parts.append(f"Val Loss: {val_metrics.get('loss', 0):.4f}")
            msg_parts.append(f"Val Acc: {val_metrics.get('acc', 0):.2f}%")

        msg_parts.append(f"LR: {train_metrics.get('lr', 0):.2e}")

        # (å¯é€‰) æ·»åŠ å†…å­˜ä½¿ç”¨
        if self.device.type == 'cuda':
            from .helpers import get_memory_usage
            mem_info = get_memory_usage()
            if mem_info:
                msg_parts.append(f"Mem: {mem_info['allocated']}")

        # è¾“å‡ºæ—¥å¿—
        log_msg = " | ".join(msg_parts)
        logger.success(log_msg)

        # è®°å½•è¯¦ç»†åŽ†å²
        epoch_history = {
            'epoch': epoch,
            **{f'train_{k}': v for k, v in train_metrics.items()},
            **{f'val_{k}': v for k, v in val_metrics.items()}
        }
        self.training_history.append(epoch_history)

    # ========================================================================
    # 6. å®žç”¨æ–¹æ³• - ä¾›å¤–éƒ¨è°ƒç”¨
    # ========================================================================

    def get_current_lr(self) -> float:
        """
        èŽ·å–å½“å‰å­¦ä¹ çŽ‡ã€‚

        è¿”å›ž:
            float: å½“å‰å­¦ä¹ çŽ‡
        """
        return self.optimizer.param_groups[0]['lr']

    def get_training_history(self) -> list:
        """
        èŽ·å–è®­ç»ƒåŽ†å²ã€‚

        è¿”å›ž:
            list: åŒ…å«æ¯ä¸ª epoch æŒ‡æ ‡çš„åˆ—è¡¨
        """
        return self.training_history

    def __repr__(self) -> str:
        return (
            f"Trainer(\n"
            f"  model={type(self.model).__name__},\n"
            f"  device={self.device},\n"
            f"  use_amp={self.use_amp},\n"
            f"  grad_accum_steps={self.grad_accum_steps},\n"
            f"  current_epoch={self.current_epoch},\n"
            f"  best_metric={self.best_metric:.4f},\n"
            f"  show_progress={self.show_progress}\n"
            f")"
        )
