# ============================================================
# 实验配置 (Experiment)
# ============================================================
experiment:
    # 实验名称，将用于日志和检查点文件夹（如果 save_dir 被设置为动态）
    name: "CIFAR10 基准测试"
    # 全局随机种子，用于确保可复现性
    # 将在 utils.helpers.set_random_seed 中设置
    seed: 42

    # (性能) 是否启用 cuDNN 自动调优
    # true: 启用 benchmark，在固定输入尺寸时可提升 20-30% 性能，但会牺牲可复现性（默认）
    # false: 禁用 benchmark，保证完全可复现，但性能较低
    # 依赖: utils.helpers.set_random_seed (enable_cudnn_benchmark)
    enable_cudnn_benchmark: true

    device: cuda

# ============================================================
# 数据集配置 (Dataset)
# ============================================================
dataset:
    # 要加载的数据集名称 (例如: MNIST, CIFAR10)
    # 必须与 utils.data._DATASET_REGISTRY 中的键匹配
    name: "CIFAR10"
    # 数据集下载和存储的根路径
    dataset_path: "./data"

# ============================================================
# 数据加载器配置 (DataLoader)
# ============================================================
# 这些参数用于在 main.py 中创建 DataLoader
# (utils.train.Trainer 不直接感知这些)
dataloader:
    # (性能) DataLoader 使用的子进程数
    # 在 Windows 上建议为 0，Linux 上 > 0
    num_workers: 8
    # num_workers: 0

    # (性能) 允许数据加载器将张量复制到 CUDA 固定内存中
    pin_memory: true

    # (性能) 保持 worker 进程在 epoch 之间存活
    # persistent_workers: false
    persistent_workers: true # (仅在 num_workers > 0 时)

    # 批次大小
    batch_size: 128

# ============================================================
# 模型配置 (Model)
# ============================================================
model:
    # 模型的架构名称
    name: "ConvNet"
    
    # Dropout 比率，通常在 0.2 到 0.5 之间
    # 过拟合调高此值，欠拟合调低此值
    dropout_rate: 0.35
    
    # 分类类别数
    # 由数据集决定的固定值，必须根据使用的数据集进行设置
    num_classes: 10
    
    # 每个阶段的残差块数量，通常在 2 到 5 之间
    # 较小的值适用于快速实验或简单任务，较大的值可能获得更高精度但也更容易过拟合且训练更慢
    num_blocks: 3

# ============================================================
# 训练协调器配置 (Training)
# ============================================================
# 本节的大部分参数由 utils.train.Trainer.from_config 直接读取
training:
    # --- 1. 核心循环参数 (在 main.py 中使用) ---

    # 总训练轮数
    epochs: 100

    # --- 2. 优化器参数 (在 main.py 中使用) ---

    # 初始学习率
    lr: 0.01
    # 使用的优化器类型 (例如: SGD, Adam)
    # 已经弃用，优化器配置见下
    # optimizer: "Adam"
    
    weight_decay: 0.0001
    momentum: 0.9

    # --- 3. 性能与优化 (由 Trainer 读取) ---

    # (性能) 是否使用自动混合精度 (AMP)
    # 依赖: utils.train.Trainer (use_amp)
    use_amp: true

    # (性能) 梯度累积步数。
    # 依赖: utils.train.Trainer (grad_accum_steps)
    grad_accum_steps: 1

    # (可选) 梯度裁剪的最大范数。如果为 null 或 0 则不使用。
    # 依赖: utils.train.Trainer (max_grad_norm)
    max_grad_norm: 1.0
    
    # 是否使用 torch.compile 优化
    use_compile: false

    # --- 4. 验证与日志 (由 Trainer 读取) ---

    # 每隔多少个 epoch 记录一次详细日志
    # 依赖: utils.train.Trainer (log_interval)
    log_interval: 1

    # 每隔多少个 epoch 运行一次验证集
    # 依赖: utils.train.Trainer (val_interval)
    val_interval: 1

    # 是否计算 Top-5 准确率 (如果数据集类别 > 5)
    # 依赖: utils.train.Trainer (compute_top5)
    compute_top5: true

    # --- 5. 早停与指标 (由 Trainer 读取) ---

    # 用于早停和保存最佳模型的指标名称
    # 必须与 utils.metrics.MetricTracker.compute() 返回的键匹配
    # 依赖: utils.train.Trainer (metric_to_track)
    metric_to_track: "acc"

    # 监控指标的模式: 'max' (越高越好) 或 'min' (越低越好)
    # 依赖: utils.train.Trainer (metric_mode)
    # 依赖: utils.early_stopping.EarlyStopper (mode)
    metric_mode: "max"

    # 早停耐心：在停止前等待多少个 epoch 没有改善
    # 依赖: utils.early_stopping.EarlyStopper (patience)
    patience: 8

    # (可选) 被视为"改善"的最小变化量
    # 依赖: utils.early_stopping.EarlyStopper (min_delta)
    min_delta: 0.0005

    # 更新 `set_postfix` (I/O) 的最小间隔（秒）
    # 依赖: utils.progress.Progress
    progress_update_interval: 1.5

# ============================================================
# 检查点配置 (Checkpoint)
# ============================================================
# 本节由 utils.train.Trainer.from_config (通过 CheckpointManager) 读取
checkpoint:
    # 是否启用检查点保存功能
    # 依赖: utils.train.Trainer.from_config
    enabled: true

    # 保存检查点（.pth 文件）的目录
    # 依赖: utils.checkpoint_manager.CheckpointManager (save_dir)
    save_dir: "./checkpoints"

    # 滚动保存最近的 K 个 epoch 检查点
    # (best_model.pth 和 interrupt_checkpoint.pth 不受此限制)
    # 依赖: utils.checkpoint_manager.CheckpointManager (max_to_keep)
    max_to_keep: 3

# ============================================================
# 日志配置 (Logging)
# ============================================================
# 本节由 utils.logger_config.setup_logging 读取
logging:
    # 保存日志文件 (例如 log_20251103.log) 的目录
    log_dir: "./logs"
    # 控制台输出的最低级别 (例如: DEBUG, INFO, WARNING)
    console_level: "INFO"
    # 文件输出的最低级别 (通常设置为 DEBUG 以便排错)
    file_level: "DEBUG"

# ============================================================
# NTFY 通知配置 (Ntfy)
# ============================================================
# 本节由 utils.train.Trainer.from_config (通过 NtfyNotifier) 读取
ntfy:
    # 是否启用 NTFY 手机通知 (true / false)
    enabled: true

    # (可选) Ntfy 服务器 URL，如果自托管的话
    # 依赖: utils.ntfy_notifier.NtfyNotifier (server_url)
    server_url: "https://ntfy.sh"

    # (可选) 目标 Ntfy 频道
    # (注意: utils.ntfy_notifier.py 中可能已硬编码)
    # 依赖: utils.ntfy_notifier.NtfyNotifier (topic)
    topic: "trouvaille_william_yK5aEPt72KfT6m9z"

# ============================================================
# 训练报告配置 (Reporter)
# ============================================================
# 本节由 utils.visualization.TrainingReporter 读取
reporter:
    # 报告保存根目录
    save_dir: "./docs"

    # 是否在报告目录中创建时间戳子目录（避免覆盖）
    # true: 创建 ./docs/report_20251104_143022/
    # false: 直接使用 ./docs/
    use_timestamp: true

    # 图表样式配置
    plots:
        # 图表分辨率 (DPI)
        dpi: 100
        # 默认图表尺寸 [width, height] (英寸)
        figure_size: [10, 6]
        # matplotlib 样式名称
        style: "seaborn-v0_8-darkgrid"

    # 可选图表开关（控制生成哪些图表）
    enable_plots:
        # 训练曲线（Loss & 准确率）
        training_curves: true
        # 混淆矩阵
        confusion_matrix: true
        # ROC 曲线
        roc_curve: true
        # 分类报告热图
        classification_report: true
        # Epoch 耗时分布
        epoch_time_distribution: true

    # ROC 曲线配置
    roc:
        # 多分类策略: 'ovr' (One-vs-Rest) 或 'ovo' (One-vs-One)
        multi_class: "ovr"

    # 混淆矩阵配置
    confusion_matrix:
        # 是否归一化显示（百分比）
        normalize: true
        # 颜色映射方案（例如: Blues, YlGnBu, Greens）
        cmap: "Blues"
# ============================================================
# 训练可视化与报告配置 (Visualization)
# ============================================================
# 本配置文件用于 utils/visualization 模块
# 仅包含当前代码中可用的 TrainingReporter 相关配置项
visualization:
    # ========================================================
    # TrainingReporter 配置
    # ========================================================
    # 功能: 生成完整的训练报告（包含图表与 Markdown 摘要）
    # 依赖: utils.visualization.TrainingReporter
    reporter:
        # 报告保存根目录
        # 依赖: TrainingReporter.__init__ (save_dir)
        save_dir: "./docs"

        # 是否为每次运行创建时间戳子目录
        # 依赖: TrainingReporter.__init__ (use_timestamp)
        use_timestamp: true

        # 图表样式配置，同 MetricsVisualizer 构造参数保持一致
        plots:
            # 图表分辨率 (DPI)
            # 依赖: utils.visualization.MetricsVisualizer (dpi)
            dpi: 100

            # 默认图表尺寸 [width, height] (英寸)
            # 依赖: utils.visualization.MetricsVisualizer (figure_size)
            figure_size: [10, 6]

            # matplotlib 样式名称
            # 依赖: utils.visualization.MetricsVisualizer (style)
            style: "seaborn-v0_8-darkgrid"

        # 可选图表开关，控制 TrainingReporter.generate_full_report 生成的图表
        enable_plots:
            training_curves: true
            confusion_matrix: true
            roc_curve: true
            classification_report: true
            epoch_time_distribution: true

        # ROC 曲线配置
        # 依赖: TrainingReporter.generate_full_report -> MetricsVisualizer.plot_roc_curve
        roc:
            multi_class: "ovr"

        # 混淆矩阵配置
        # 依赖: TrainingReporter.generate_full_report -> MetricsVisualizer.plot_confusion_matrix
        confusion_matrix:
            normalize: true
            cmap: "Blues"
# ============================================================
# 优化器配置 (Optimizers)
# ============================================================
# 本配置文件用于 utils/optimizers 模块和 PyTorch 内置优化器
# 提供多种优化器及其超参数配置
optimizer:
    # 优化器类型选择
    # 可选值: 'SGD', 'Adam', 'AdamW', 'AdamP', 'Lion', 'MadGrad'
    # 依赖:
    #   - PyTorch 内置: torch.optim (SGD, Adam, AdamW)
    #   - 自定义实现: utils.optimizers (AdamP, Lion, MadGrad)
    #
    # 推荐选择指南:
    #   - SGD: 经典优化器，收敛稳定但需精细调参
    #          适用场景: ResNet 等经典模型、充足调参时间
    #          论文: Bottou (1991)
    #   - Adam: 自适应学习率，收敛快但泛化可能较差
    #           适用场景: Transformer、快速实验
    #           论文: Kingma & Ba (2015)
    #   - AdamW: Adam + 解耦权重衰减，泛化更好（推荐）
    #            适用场景: 大多数场景的首选
    #            论文: Loshchilov & Hutter (2019)
    #   - AdamP: Adam + 投影约束，抑制权重范数膨胀
    #            适用场景: 深层网络、长时间训练
    #            论文: Heo et al. (2020)
    #   - Lion: 符号动量优化器，内存效率高
    #           适用场景: 大模型、显存受限
    #           论文: Chen et al. (2023)
    #   - MadGrad: 动量化自适应双平均，鲁棒性强
    #              适用场景: 学习率敏感的任务
    #              论文: Defazio & Jelassi (2021)
    type: "AdamW"

    # ========================================================
    # 通用参数（适用于所有优化器）
    # ========================================================

    # 初始学习率
    # 推荐范围:
    #   - SGD: 0.01 - 0.1
    #   - Adam/AdamW: 0.0001 - 0.001
    #   - AdamP: 0.0001 - 0.001
    #   - Lion: 0.00001 - 0.0001 (通常是 Adam 的 1/3 到 1/10)
    #   - MadGrad: 0.001 - 0.01
    # 注意: 不同优化器对学习率的敏感度不同
    lr: 0.001

    # L2 正则化系数（权重衰减）
    # 推荐范围:
    #   - 一般任务: 0.0001 - 0.001
    #   - 小数据集: 0.001 - 0.01 (更强正则化)
    #   - 大数据集: 0.00001 - 0.0001 (较弱正则化)
    # 注意: AdamW 使用解耦权重衰减，效果更稳定
    weight_decay: 0.0001

    # ========================================================
    # SGD 专用参数
    # ========================================================
    # 依赖: torch.optim.SGD
    sgd:
        # 动量系数
        # 推荐: 0.9（标准设置）
        # 取值范围: [0.0, 1.0]
        # 作用: 加速收敛、减少震荡
        momentum: 0.9

        # 是否使用 Nesterov 动量
        # 推荐: true（收敛更快）
        # 论文: Nesterov (1983)
        nesterov: true

        # 动量阻尼
        # 推荐: 0.0（标准设置）
        # 取值范围: [0.0, 1.0]
        # 作用: 抑制动量过大
        dampening: 0.0

    # ========================================================
    # Adam / AdamW 专用参数
    # ========================================================
    # 依赖: torch.optim.Adam, torch.optim.AdamW
    adam:
        # 一阶和二阶矩估计的指数衰减率
        # 推荐: [0.9, 0.999]（标准设置）
        # betas[0]: 一阶矩（梯度）的衰减率
        #   - 较小值（如 0.8）: 对最近梯度更敏感
        #   - 较大值（如 0.95）: 更平滑的梯度估计
        # betas[1]: 二阶矩（梯度平方）的衰减率
        #   - 通常保持 0.999 不变
        betas: [0.9, 0.999]

        # 数值稳定性常数（防止除零）
        # 推荐: 1e-8（标准设置）
        # 取值范围: [1e-10, 1e-6]
        # 注意: 过小可能导致数值不稳定
        eps: 1.0e-8

        # 是否使用 AMSGrad 变体
        # 推荐: false（标准 Adam 已足够）
        # 适用场景: 训练不稳定、需要更强的二阶矩估计
        # 论文: Reddi et al. (2018)
        amsgrad: false

    # ========================================================
    # AdamP 专用参数
    # ========================================================
    # 依赖: utils.optimizers.AdamP
    # 论文: Slowing Down the Weight Norm Increase in Momentum-based Optimizers (CVPR 2021)
    adamp:
        # 一阶和二阶矩估计的指数衰减率
        # 推荐: [0.9, 0.999]（与 Adam 相同）
        betas: [0.9, 0.999]

        # 数值稳定性常数
        # 推荐: 1e-8
        eps: 1.0e-8

        # 投影半径（关键参数）
        # 推荐: 0.1（标准设置）
        # 取值范围: [0.01, 1.0]
        # 作用: 控制权重范数增长速度
        #   - 较小值（如 0.01）: 强约束，适用于深层网络
        #   - 较大值（如 1.0）: 弱约束，接近标准 Adam
        delta: 0.1

        # 权重衰减比率（关键参数）
        # 推荐: 0.1（标准设置）
        # 取值范围: [0.0, 1.0]
        # 作用: 控制权重衰减在投影中的权重
        #   - 0.0: 完全忽略权重衰减
        #   - 1.0: 完全使用权重衰减
        wd_ratio: 0.1

        # 是否使用 Nesterov 动量
        # 推荐: true（收敛更快）
        nesterov: true

    # ========================================================
    # Lion 专用参数
    # ========================================================
    # 依赖: utils.optimizers.Lion
    # 论文: Symbolic Discovery of Optimization Algorithms (ICML 2023)
    # 特点: 使用符号运算代替指数移动平均，内存效率高
    lion:
        # 动量参数
        # 推荐: [0.9, 0.99]（标准设置）
        # 注意: 与 Adam 的 betas 语义不同
        # betas[0]: 更新时使用的动量
        # betas[1]: 计算梯度时使用的动量
        betas: [0.9, 0.99]

        # 重要: Lion 的学习率通常比 Adam 小 1/3 到 1/10
        # 推荐学习率: 0.0001 (如果 Adam 使用 0.001)
        # 原因: Lion 使用符号梯度，步长更激进

        # Lion 特点:
        #   - 优点: 内存占用低（约为 Adam 的 50%）、收敛快
        #   - 缺点: 对学习率敏感、可能需要额外的权重衰减

    # ========================================================
    # MadGrad 专用参数
    # ========================================================
    # 依赖: utils.optimizers.MadGrad
    # 论文: Adaptivity without Compromise (NeurIPS 2021)
    # 特点: 动量化自适应双平均，对学习率不敏感
    madgrad:
        # 动量系数
        # 推荐: 0.9（标准设置）
        # 取值范围: [0.0, 1.0]
        # 作用: 平滑梯度估计
        momentum: 0.9

        # 数值稳定性常数
        # 推荐: 1e-6（比 Adam 略大）
        # 取值范围: [1e-8, 1e-5]
        eps: 1.0e-6

        # MadGrad 特点:
        #   - 优点: 对学习率不敏感、鲁棒性强
        #   - 缺点: 收敛速度略慢于 AdamW
        #   - 适用场景: 学习率难以调优的任务

# ============================================================
# 训练回调配置 (Callbacks)
# ============================================================
# 本配置文件用于 utils/callbacks 模块
# Callbacks 提供训练过程中的钩子机制，用于监控、调试和自动化任务
callbacks:
    # ========================================================
    # Timer 回调配置
    # ========================================================
    # 功能: 精确测量训练各阶段的耗时
    # 依赖: utils.callbacks.Timer
    # 适用场景: 性能分析、瓶颈定位、训练时间估算
    timer:
        # 是否启用计时器（外部逻辑据此决定是否实例化 Timer）
        enabled: true

        # 训练时间上限，格式为 "DD:HH:MM:SS"
        # 依赖: utils.callbacks.Timer (duration 参数)
        # 设置为 null 表示不限制训练时间
        duration: null

        # 计时粒度，仅支持 'step' 或 'epoch'
        # 依赖: utils.callbacks.Timer (interval 参数)
        interval: "epoch"

        # 是否输出详细日志
        # 依赖: utils.callbacks.Timer (verbose 参数)
        verbose: false

    # ========================================================
    # LearningRateMonitor 回调配置
    # ========================================================
    # 功能: 监控并记录学习率变化
    # 依赖: utils.callbacks.LearningRateMonitor
    # 适用场景: 学习率调度调试、训练过程可视化
    lr_monitor:
        # 是否启用学习率监控
        enabled: true

        # 记录间隔: 'step'、'epoch' 或 null（由调度器决定）
        # 依赖: utils.callbacks.LearningRateMonitor (logging_interval 参数)
        logging_interval: "epoch"

        # 是否记录动量
        # 依赖: utils.callbacks.LearningRateMonitor (log_momentum 参数)
        log_momentum: false

        # 是否记录权重衰减
        # 依赖: utils.callbacks.LearningRateMonitor (log_weight_decay 参数)
        log_weight_decay: false

    # ========================================================
    # BatchSizeFinder 回调配置
    # ========================================================
    # 功能: 自动查找最优批大小
    # 依赖: utils.callbacks.BatchSizeFinder
    # 适用场景: 新模型、新硬件、最大化 GPU 利用率
    batch_size_finder:
        # 是否启用批大小查找器
        enabled: false

        # 搜索模式: 'power' 或 'binsearch'
        # 依赖: utils.callbacks.BatchSizeFinder (mode 参数)
        mode: "power"

        # 每次尝试的训练步数
        # 依赖: utils.callbacks.BatchSizeFinder (steps_per_trial 参数)
        steps_per_trial: 3

        # 初始批大小
        # 依赖: utils.callbacks.BatchSizeFinder (init_val 参数)
        init_val: 16

        # 最大尝试次数
        # 依赖: utils.callbacks.BatchSizeFinder (max_trials 参数)
        max_trials: 25

        # 安全边界 (仅对 binsearch 模式生效)
        # 依赖: utils.callbacks.BatchSizeFinder (margin 参数)
        margin: 0.05

        # 批大小上限
        # 依赖: utils.callbacks.BatchSizeFinder (max_val 参数)
        max_val: 1024
# ============================================================
# 数据增强配置 (Augmentation)
# ============================================================
# 本配置文件用于 utils/augmentation 模块
# 提供多种预定义策略和自定义增强管道配置
augmentation:
    # 是否启用数据增强（全局开关）
    # 禁用后将跳过所有数据增强，仅使用原始数据
    enabled: true

    # 增强策略选择: 'basic', 'simclr', 'strong', 'custom'
    # 依赖: utils.augmentation.pipeline
    #   - 'basic': 基础增强策略（随机裁剪、翻转、轻度颜色抖动）
    #              适用场景: 标准分类任务、快速实验
    #              性能影响: 轻微
    #   - 'simclr': SimCLR 风格对比学习增强（强烈颜色抖动、高斯模糊）
    #               适用场景: 自监督学习、对比学习任务
    #               性能影响: 中等
    #   - 'strong': 强增强策略（包含噪声、遮挡、强变换）
    #               适用场景: 数据量少、需要大量数据增强的场景
    #               性能影响: 较大
    #   - 'custom': 自定义增强管道（使用下方 custom_transforms 配置）
    #               适用场景: 特殊需求、精细调优
    strategy: "basic"

    # 自定义增强管道配置（仅当 strategy='custom' 时生效）
    # 依赖: utils.augmentation 模块中的各个变换类
    custom_transforms:
        # ========================================================
        # 几何变换 (Geometric Transforms)
        # ========================================================

        # 随机裁剪并调整大小
        # 依赖: utils.augmentation.geometric.RandomCropAndResize
        random_crop_and_resize:
            # 是否启用此变换
            enabled: true
            # 输出图像尺寸 [height, width]
            size: [32, 32]
            # 裁剪区域面积相对于原图的比例范围 [min, max]
            # 推荐: [0.08, 1.0] (标准 ImageNet 设置)
            scale: [0.08, 1.0]
            # 裁剪区域的宽高比范围 [min, max]
            # 推荐: [0.75, 1.33] (3/4 到 4/3)
            ratio: [0.75, 1.33]

        # 随机水平翻转
        # 依赖: utils.augmentation.geometric.RandomHorizontalFlip
        random_horizontal_flip:
            enabled: true
            # 翻转概率
            # 推荐: 0.5 (50% 概率翻转)
            p: 0.5

        # 随机旋转
        # 依赖: utils.augmentation.geometric.RandomRotation
        random_rotation:
            # 默认禁用，因为分类任务通常不需要旋转
            enabled: false
            # 旋转角度范围 [-degrees, +degrees]
            # 推荐: 15（轻度旋转）到 30（中度旋转）
            # 注意: 过大的旋转可能导致信息丢失
            degrees: 15

        # 中心裁剪
        # 依赖: utils.augmentation.geometric.CenterCrop
        center_crop:
            # 通常用于测试集，训练集较少使用
            enabled: false
            # 裁剪尺寸 [height, width]
            size: [32, 32]

        # ========================================================
        # 颜色变换 (Color Transforms)
        # ========================================================

        # 颜色抖动（亮度、对比度、饱和度、色调的组合变换）
        # 依赖: utils.augmentation.color.ColorJitter
        color_jitter:
            enabled: true
            # 亮度抖动强度 [1-brightness, 1+brightness]
            # 推荐: 0.4 (基础增强) 到 0.8 (SimCLR)
            brightness: 0.4
            # 对比度抖动强度 [1-contrast, 1+contrast]
            contrast: 0.4
            # 饱和度抖动强度 [1-saturation, 1+saturation]
            saturation: 0.4
            # 色调抖动强度 [-hue, +hue]（取值范围 [0, 0.5]）
            # 推荐: 0.1 (基础增强) 到 0.2 (强增强)
            hue: 0.1

        # 随机亮度调整
        # 依赖: utils.augmentation.color.RandomBrightness
        random_brightness:
            # 通常使用 ColorJitter 代替单独的亮度调整
            enabled: false
            brightness_factor: 0.4

        # 随机对比度调整
        # 依赖: utils.augmentation.color.RandomContrast
        random_contrast:
            enabled: false
            contrast_factor: 0.4

        # 随机饱和度调整
        # 依赖: utils.augmentation.color.RandomSaturation
        random_saturation:
            enabled: false
            saturation_factor: 0.4

        # 随机色调调整
        # 依赖: utils.augmentation.color.RandomHue
        random_hue:
            enabled: false
            hue_factor: 0.1

        # 随机转换为灰度图
        # 依赖: utils.augmentation.color.ToGrayscale
        to_grayscale:
            # 适用场景: 对比学习、颜色不变性学习
            enabled: false
            # 转换概率
            p: 0.2

        # ========================================================
        # 滤波器 (Filters)
        # ========================================================

        # 高斯模糊
        # 依赖: utils.augmentation.filter.GaussianBlur
        gaussian_blur:
            # 适用场景: SimCLR 对比学习、减少高频噪声
            enabled: false
            # 高斯核大小（奇数）
            # 推荐: 3 (轻度模糊) 到 7 (中度模糊)
            kernel_size: 3
            # 高斯核标准差范围 [min, max]
            # 推荐: [0.1, 2.0]
            sigma: [0.1, 2.0]

        # Sobel 边缘检测滤波器
        # 依赖: utils.augmentation.filter.SobelFilter
        sobel_filter:
            # 适用场景: 边缘特征学习、特殊任务
            # 注意: 通常不用于标准分类任务
            enabled: false

        # ========================================================
        # 噪声 (Noise)
        # ========================================================

        # 高斯噪声
        # 依赖: utils.augmentation.noise.GaussianNoise
        gaussian_noise:
            # 适用场景: 提升鲁棒性、模拟传感器噪声
            enabled: false
            # 噪声均值
            mean: 0.0
            # 噪声标准差
            # 推荐: 0.01 (轻度噪声) 到 0.1 (中度噪声)
            # 注意: 过大会严重破坏图像信息
            std: 0.05

        # ========================================================
        # 遮挡 (Occlusion)
        # ========================================================

        # 随机擦除（Random Erasing）
        # 依赖: utils.augmentation.occlusion.RandomErasing
        random_erasing:
            # 适用场景: 提升遮挡鲁棒性、防止过拟合
            # 论文: Random Erasing Data Augmentation (AAAI 2020)
            enabled: false
            # 应用概率
            p: 0.5
            # 擦除区域面积相对于图像的比例范围 [min, max]
            # 推荐: [0.02, 0.33]
            scale: [0.02, 0.33]
            # 擦除区域的宽高比范围 [min, max]
            # 推荐: [0.3, 3.3]
            ratio: [0.3, 3.3]

        # Cutout（裁剪遮挡）
        # 依赖: utils.augmentation.occlusion.CutOut
        cutout:
            # 适用场景: 分类任务、防止过拟合
            # 论文: Improved Regularization of Convolutional Neural Networks with Cutout (2017)
            enabled: false
            # 遮挡的孔洞数量
            n_holes: 1
            # 每个孔洞的边长（像素）
            # 推荐: 图像尺寸的 1/4 到 1/2
            # CIFAR-10 (32x32): 16
            # ImageNet (224x224): 56
            length: 16

    # ========================================================
    # 预定义策略的覆盖参数（可选）
    # ========================================================
    # 这些参数允许在使用预定义策略时覆盖默认配置
    # 仅当 strategy 为 'basic', 'simclr', 'strong' 时生效
    strategy_overrides:
        # SimCLR 策略参数覆盖
        # 依赖: utils.augmentation.pipeline.get_simclr_augmentation
        simclr:
            # 颜色抖动强度（0.0 到 1.0）
            # 默认: 0.8
            color_jitter_strength: 0.8
            # 高斯模糊应用概率
            # 默认: 0.5
            gaussian_blur_p: 0.5
            # 输出图像尺寸
            # 默认: [32, 32]
            image_size: [32, 32]

        # 基础策略参数覆盖
        # 依赖: utils.augmentation.pipeline.get_basic_augmentation
        basic:
            # 水平翻转概率
            # 默认: 0.5
            horizontal_flip_p: 0.5
            # 颜色抖动强度
            # 默认: 0.4
            color_jitter_strength: 0.4

        # 强增强策略参数覆盖
        # 依赖: utils.augmentation.pipeline.get_strong_augmentation
        strong:
            # 随机擦除概率
            # 默认: 0.5
            random_erasing_p: 0.5
            # Cutout 孔洞数量
            # 默认: 1
            cutout_n_holes: 1
            # Cutout 孔洞边长
            # 默认: 16
            cutout_length: 16

    # ========================================================
    # 性能优化配置（高级）
    # ========================================================
    performance:
        # 是否使用 CUDA 加速（如果可用）
        # 依赖: torch.cuda.is_available()
        # 注意: 并非所有变换都支持 CUDA 加速
        use_cuda: false

        # 数据增强的并行度
        # 依赖: DataLoader 的 num_workers
        # 推荐: 与 dataloader.num_workers 保持一致
        # 注意: 过高可能导致内存不足
        num_workers: 4

        # 是否缓存预处理结果（实验性功能）
        # 适用场景: 数据集较小、增强策略固定
        # 注意: 会占用额外内存
        cache_augmented_data: false

